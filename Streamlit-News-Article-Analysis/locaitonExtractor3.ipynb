{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "from geopy.geocoders import Nominatim\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain\n",
    "# Langchain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, LLMChain ,LLMCheckerChain\n",
    "from langchain.callbacks import wandb_tracing_enabled\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    StringPromptTemplate\n",
    ")\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.chains import SimpleSequentialChain ,SequentialChain\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent,BaseMultiActionAgent\n",
    "from langchain.agents import AgentType, initialize_agent,AgentExecutor,BaseSingleActionAgent\n",
    "from langchain.tools import tool\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser,Agent\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, OutputParserException\n",
    "import re\n",
    "from langchain.agents import Tool, AgentExecutor, BaseSingleActionAgent\n",
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun,\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForChainRun,\n",
    "    CallbackManagerForToolRun,\n",
    "    Callbacks,\n",
    ")\n",
    "from newspaper import Config, Article, Source\n",
    "import requests\n",
    "from utils.Webscraper import Webscraper\n",
    "import tiktoken\n",
    "\n",
    "from supabase import create_client, Client\n",
    "import postgrest\n",
    "from postgrest.exceptions import APIError\n",
    "import newspaper\n",
    "\n",
    "webscraper = Webscraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from the .env file\n",
    "load_dotenv('./.env')\n",
    "\n",
    "# Access the variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_TRACING_V2=os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_ENDPOINT=os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "# Access the variables\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "# Set the environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = LANGCHAIN_TRACING_V2\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGCHAIN_ENDPOINT\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coordinates (-8.3304977, 115.0906401)\n"
     ]
    }
   ],
   "source": [
    "# @tool(\"get_location\",return_direct=False)\n",
    "def get_coordinates(location:str) -> tuple[float, float]:\n",
    "    \"\"\"Returns the latitude and longitude of a location.Location should include any landmarks,cities, countries and addresses, output an address searchable in googleMaps be as specific as possible.\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"geoapi_explorer\")\n",
    "    try:\n",
    "        location_info = geolocator.geocode(location)\n",
    "    except:\n",
    "        return \"Location Input must be more general, E.g Country,City,state,street\"\n",
    "    \n",
    "    if location_info:\n",
    "        latitude = location_info.latitude\n",
    "        longitude = location_info.longitude\n",
    "        return (latitude, longitude)\n",
    "    else:\n",
    "        return \"Location Input must be more general, E.g Country,City,state,street\"\n",
    "\n",
    "\n",
    "# use the function\n",
    "coordinates = get_coordinates(\"Bali, Indonesia\")\n",
    "print(f'coordinates',coordinates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disruption Event classifier 0|1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['article'], output_parser=None, partial_variables={}, template=\"Role:You are a Binary Classifier,your goal is to classify if the given news article is a vaild disruption event article or not.\\n    Conditions:\\n    1. A disruption event can be a Natural Disaster Example but not limited to: Earthquake,Flood,Extreme Weather. OR Man-Made but not limited to: Geo-Political,Protest/Riot,Airport Disruption.\\n    2. The disruption event the news article is reporting, must be a 'live' event, meaning it is currently happening. Not an article reporting on a past event.\\n\\n    Article: {article}\\n\\n    TASK: Given youre Role and the Conditions, Classify if the given news article is a vaild disruption event article or not. Think through and give reasoning for your decision. Must Output 0 for False and 1 for True.\\n    \", template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0613', temperature=1.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='function', output_parser=JsonOutputFunctionsParser(args_only=True, strict=False), return_final_only=True, llm_kwargs={'functions': [{'name': 'output_formatter', 'description': 'Output formatter. Should always be used to format your response to the user.', 'parameters': {'name': 'binary_classifier_article_schema', 'description': 'Binary Classifier Schema for Article, 0 for False and 1 for True', 'type': 'object', 'properties': {'isDisruptionEvent': {'type': 'boolean'}, 'Reason': {'type': 'string'}}, 'required': ['isDisruptionEvent', 'Reason']}}], 'function_call': {'name': 'output_formatter'}})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0613\", temperature=1)\n",
    "classifier_article_schema = {\n",
    "    \"name\": \"binary_classifier_article_schema\",\n",
    "    \"description\": \"Binary Classifier Schema for Article, 0 for False and 1 for True\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"isDisruptionEvent\": {\n",
    "        \"type\": \"boolean\"\n",
    "      },\n",
    "      \"Reason\": {\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"isDisruptionEvent\", \"Reason\"]\n",
    "  }\n",
    "\n",
    "classifierprompt = PromptTemplate(\n",
    "    template = \"\"\"Role:You are a Binary Classifier,your goal is to classify if the given news article is a vaild disruption event article or not.\n",
    "    Conditions:\n",
    "    1. A disruption event can be a Natural Disaster Example but not limited to: Earthquake,Flood,Extreme Weather. OR Man-Made but not limited to: Geo-Political,Protest/Riot,Airport Disruption.\n",
    "    2. The disruption event the news article is reporting, must be a 'live' event, meaning it is currently happening. Not an article reporting on a past event.\n",
    "\n",
    "    Article: {article}\n",
    "\n",
    "    TASK: Given youre Role and the Conditions, Classify if the given news article is a vaild disruption event article or not. Think through and give reasoning for your decision. Must Output 0 for False and 1 for True.\n",
    "    \"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "ArticleClassifier = create_structured_output_chain(output_schema=classifier_article_schema,llm = llm,prompt=classifierprompt)\n",
    "ArticleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functions': [{'name': 'output_formatter',\n",
       "   'description': 'Output formatter. Should always be used to format your response to the user.',\n",
       "   'parameters': {'name': 'binary_classifier_article_schema',\n",
       "    'description': 'Binary Classifier Schema for Article, 0 for False and 1 for True',\n",
       "    'type': 'object',\n",
       "    'properties': {'isDisruptionEvent': {'type': 'boolean'},\n",
       "     'Reason': {'type': 'string'}},\n",
       "    'required': ['isDisruptionEvent', 'Reason']}}],\n",
       " 'function_call': {'name': 'output_formatter'}}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema2 = ArticleClassifier.llm_kwargs\n",
    "schema2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'object', 'properties': {'isDisruptionEvent': {'type': 'boolean'}, 'Reason': {'type': 'string'}}, 'required': ['isDisruptionEvent', 'Reason']}\n"
     ]
    }
   ],
   "source": [
    "def extract_json_schema(data):\n",
    "    # Check if the 'functions' key exists in the data\n",
    "    if 'functions' in data:\n",
    "        # Iterate through the functions\n",
    "        for function in data['functions']:\n",
    "            # Check if the 'parameters' key exists in the function\n",
    "            if 'parameters' in function:\n",
    "                # Check if the 'type' key is 'object' in the parameters\n",
    "                if function['parameters'].get('type') == 'object':\n",
    "                    # Return the properties and required fields of the object schema\n",
    "                    properties = function['parameters'].get('properties', {})\n",
    "                    required = function['parameters'].get('required', [])\n",
    "                    return {'type': 'object', 'properties': properties, 'required': required}\n",
    "    \n",
    "    # If schema extraction fails, return None\n",
    "    return None\n",
    "\n",
    "# Example schema data\n",
    "schema_data = {\n",
    "    'functions': [\n",
    "        {\n",
    "            'name': 'output_formatter',\n",
    "            'description': 'Output formatter. Should always be used to format your response to the user.',\n",
    "            'parameters': {\n",
    "                'name': 'binary_classifier_article_schema',\n",
    "                'description': 'Binary Classifier Schema for Article, 0 for False and 1 for True',\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'isDisruptionEvent': {'type': 'boolean'},\n",
    "                    'Reason': {'type': 'string'}\n",
    "                },\n",
    "                'required': ['isDisruptionEvent', 'Reason']\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'function_call': {'name': 'output_formatter'}\n",
    "}\n",
    "\n",
    "# Extract the JSON schema\n",
    "json_schema = extract_json_schema(schema2)\n",
    "\n",
    "# Print the extracted JSON schema\n",
    "print(json_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 'not a boolean testing' is not of type 'boolean'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['isDisruptionEvent']:\n",
      "    {'type': 'boolean'}\n",
      "\n",
      "On instance['isDisruptionEvent']:\n",
      "    'not a boolean testing'\n"
     ]
    }
   ],
   "source": [
    "import jsonschema\n",
    "from jsonschema import ValidationError\n",
    "# schema = {\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"isDisruptionEvent\": {\"type\": \"boolean\"},\n",
    "#         \"Reason\": {\"type\": \"string\"}\n",
    "#     },\n",
    "#     \"required\": [\"isDisruptionEvent\", \"Reason\"]\n",
    "# }\n",
    "\n",
    "sample_output = {\n",
    "    \"isDisruptionEvent\": 'not a boolean testing',\n",
    "    \"Reason\": \"The article is reporting on a live event, a protest in Hong Kong.\"\n",
    "}\n",
    "# schema = ArticleClassifier.llm_kwargs\n",
    "\n",
    "# Create a validator based on the JSON_SCHEMA\n",
    "validator = jsonschema.Draft7Validator(json_schema)\n",
    "\n",
    "# Check if the output is valid\n",
    "errors = list(validator.iter_errors(sample_output))\n",
    "\n",
    "if errors:\n",
    "    error_messages = [str(error) for error in errors]\n",
    "    print(False, \", \".join(error_messages))  # Output is invalid, print the validation error messages\n",
    "else:\n",
    "    print(True, \"\")  # Output is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.check_schema(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'functions': [{'name': 'output_formatter',\n",
       "   'description': 'Output formatter. Should always be used to format your response to the user.',\n",
       "   'parameters': {'name': 'binary_classifier_article_schema',\n",
       "    'description': 'Binary Classifier Schema for Article, 0 for False and 1 for True',\n",
       "    'type': 'object',\n",
       "    'properties': {'isDisruptionEvent': {'type': 'boolean'},\n",
       "     'Reason': {'type': 'string'}},\n",
       "    'required': ['isDisruptionEvent', 'Reason']}}],\n",
       " 'function_call': {'name': 'output_formatter'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArticleClassifier.llm_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationExtractorSchema = {\n",
    "    \"name\": \"locationExtractorSchema\",\n",
    "    \"description\": \"Format and extract the disruption event location from the given text\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"Description\": \"Location of Disruption Event.Location should include any landmarks,cities, countries and addresses, output an address searchable in googleMaps be as specific as possible.\"\n",
    "        },\n",
    "        \"Country\": {\n",
    "            \"type\": \"string\",\n",
    "            \"Description\": \"Country where the disruption event is happening\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"location\", \"Country\"]\n",
    "}\n",
    "\n",
    "locationExtractorPrompt = PromptTemplate(\n",
    "    template = \"\"\"Role:You are a Location Extractor,your goal is to extract the location of the disruption event from the given text. Location of Disruption Event. Examples: 1.French Pass, New Zealand 2.Xiamen Fujian Chain,3.Perry, Florida, USA. \\n\\nArticle:{article}\\n\\nTask: Extract Location of disruption event.Location should include any landmarks,cities, countries and addresses, output an address searchable in googleMaps be as specific as possible.Feedback:{feedback}\"\"\",\n",
    "    input_variables=[\"article\",\"feedback\"]\n",
    ")\n",
    "\n",
    "locationExtractor = create_structured_output_chain(output_schema=locationExtractorSchema,llm = llm,prompt=locationExtractorPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventDetails_schema = {\n",
    "    \"name\": \"eventDetails_schema\",\n",
    "    \"description\": \"Format and extract the disruption event details from the given article\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"Description\": \"Name of Disruption Event, Includes some sort of key identifier\"\n",
    "        },\n",
    "        \"disruptionType\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Type of disruption event. Max 3 words\"\n",
    "        },\n",
    "        \"severity\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"Quantifiable Severity metrics of the disruption event.\"\n",
    "        },\n",
    "        \"date\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Date of Disruption Event, ISO 8601 format YYYY-MM-DD\",\n",
    "            \"format\": \"date\"\n",
    "        },\n",
    "        \"radius\": {\n",
    "            \"type\": \"number\",\n",
    "            \"Description\": \"Estimated Radius of Disruption Event, in KM\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"disruptionType\",\"severity\",\"date\",\"radius\"]\n",
    "}\n",
    "\n",
    "eventDetailsPrompt = PromptTemplate(\n",
    "    template = \"\"\"Role:You are a Disruption event News Analyst, your goal is to extract the details of the disruption event from the given article. \\n\\nArticle:{article}\\nFeedback:{feedback}\\n\\nTask: Extract the details of the disruption event from the given article.Details include:\\n1.Name of Disruption Event, Includes some sort of key identifier,with indication of severity\\n2.Type of disruption event ,Max 3 words.\\n3.Quantifiable Severity metrics of the disruption event.Extract multiple metrics,E.g Casualities,Cost damage etc.Example Severity:\"Magnitude of 5.6, Depth of 170km. tremor was felt widely across parts, but no damage was caused overall\"\\n4.Date of Disruption Event, in YYYY-MM-DD.\\n5.Estimated Radius of imapact of Disruption Event, in KM.\"\"\",\n",
    "    input_variables=[\"article\",\"feedback\"]\n",
    ")\n",
    "\n",
    "eventDetails = create_structured_output_chain(output_schema=eventDetails_schema,llm = llm,prompt=eventDetailsPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main input logic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class outputValidator:\n",
    "    \"\"\"Validates json output of any llmchain, given that it's created with the create_structured_output_chain function\"\"\"\n",
    "\n",
    "    def _getOutputSchemaMapping(self, LLMChain:LLMChain) -> dict:\n",
    "        \"\"\"Returns the supposed output schema of the given LLMChain \n",
    "        \n",
    "        Example llm_kwargs:\n",
    "        {'functions': [{'name': 'output_formatter',\n",
    "   'description': 'Output formatter. Should always be used to format your response to the user.',\n",
    "   'parameters': {'name': 'binary_classifier_article_schema',\n",
    "    'description': 'Binary Classifier Schema for Article, 0 for False and 1 for True',\n",
    "    'type': 'object',\n",
    "    'properties': {'isDisruptionEvent': {'type': 'boolean'},\n",
    "     'Reason': {'type': 'string'}},\n",
    "    'required': ['isDisruptionEvent', 'Reason']}}],\n",
    "    'function_call': {'name': 'output_formatter'}}\n",
    "    \"\"\"\n",
    "        output_schema = LLMChain.llm_kwargs\n",
    "        # Create a dictionary mapping with Key as Key and Value as type\n",
    "        output_schema = {key:value[\"type\"] for key,value in output_schema.items()}\n",
    "        return output_schema\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def validate(cls, LLMChain:LLMChain,output:dict) -> Tuple[bool,str]:\n",
    "        \"\"\"Validates the output of the given llmchain\n",
    "        Args:\n",
    "            LLMChain (LLMChain): The LLMChain to validate\n",
    "            output (dict): The output of the LLMChain\n",
    "        Returns:\n",
    "            Tuple[bool,str]: A tuple containing a boolean and a string, the boolean is True if the output is valid, False if not. \n",
    "            The string is the reason for the boolean value. If the boolean is True, the string will be empty.\n",
    "            The string might be used to give feedback to LLMChain to improve the output.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if the output is a dict\n",
    "        if not isinstance(output,dict):\n",
    "            return (False,\"The output is not JSON object (dict)\")\n",
    "        \n",
    "        #TODO: Check if the output is a valid json object from the schema\n",
    "        return (True,\"\")\n",
    "\n",
    "class MDE: \n",
    "    \"\"\"Main Disruption Event Class, Handles the LLM chaining of input and outputs\"\"\"\n",
    "\n",
    "    class MDE:\n",
    "        binaryClassifier: LLMChain = ArticleClassifier\n",
    "        locationExtractor: LLMChain = locationExtractor\n",
    "        eventDetails: LLMChain = eventDetails \n",
    "\n",
    "        # The function to get the coordinates of a location\n",
    "        get_coordinates: Callable = get_coordinates\n",
    "        webscraper: Webscraper = webscraper\n",
    "\n",
    "        article_token_threshold: int = 1500\n",
    "        \"\"\"The number of tokens to use the article summary instead of the full article\"\"\"\n",
    "\n",
    "        @staticmethod\n",
    "        def _articleExtraction(url) -> str:\n",
    "            \"\"\"Extracts the article text from the given url\"\"\"\n",
    "            try:\n",
    "                article = webscraper.scrape(url)\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error: Article Extraction Failed, {e}\") from e\n",
    "            return article\n",
    "\n",
    "        @staticmethod\n",
    "        def _binaryClassifier(article: Article) -> bool:\n",
    "            \"\"\"Classifies if the given article is a valid disruption event article or not\"\"\"\n",
    "            try:\n",
    "                # Get number of tokens for the article\n",
    "                num_tokens = MDE.num_tokens_from_string(article.additional_data[\"text_body\"], \"cl100k_base\")\n",
    "                if num_tokens > MDE.article_token_threshold:\n",
    "                    logger.info(f'Article Length: {num_tokens} tokens, using article summary instead')\n",
    "                    result = MDE.binaryClassifier.run(article=article.summary)\n",
    "                else:\n",
    "                    result = MDE.binaryClassifier.run(article=article.additional_data[\"text_body\"])\n",
    "                # Validate the output\n",
    "                validation_results = outputValidator.validate(MDE.binaryClassifier, result)\n",
    "                if not validation_results[0]:\n",
    "                    raise Exception(validation_results[1])\n",
    "\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error: Binary Classification Failed -> {e}\") from e\n",
    "        \n",
    "            logger.info(f'Successfully classified isDisruptionEventarticle: {result[\"isDisruptionEvent\"]}')\n",
    "            return result[\"isDisruptionEvent\"]\n",
    "    \n",
    "        @staticmethod\n",
    "        def _locationExtractor(article: Article, feedback: str) -> str:\n",
    "            \"\"\"Extracts the location of the disruption event from the given article\"\"\"\n",
    "            try:\n",
    "                # Get number of tokens for the article\n",
    "                num_tokens = MDE.num_tokens_from_string(article.additional_data[\"text_body\"], \"cl100k_base\")\n",
    "                if num_tokens > MDE.article_token_threshold:\n",
    "                    logger.info(f'Article Length: {num_tokens} tokens, using article summary instead')\n",
    "                    result = MDE.locationExtractor.run(article=article.summary, feedback=feedback)\n",
    "                else:\n",
    "                    result = MDE.locationExtractor.run(article=article.additional_data[\"text_body\"], feedback=feedback)\n",
    "                # Validate the output\n",
    "                validation_results = outputValidator.validate(MDE.locationExtractor, result)\n",
    "                if not validation_results[0]:\n",
    "                    raise Exception(validation_results[1])\n",
    "\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error: Location Extraction Failed -> {e}\") from e\n",
    "        \n",
    "            logger.info(f'Successfully extracted disruption location: {result[\"location\"]}')\n",
    "            return result[\"location\"]\n",
    "\n",
    "        @staticmethod\n",
    "        def _eventDetails(article: Article, feedback: str) -> dict:\n",
    "            \"\"\"Extracts the event details of the disruption event from the given article\"\"\"\n",
    "            try:\n",
    "                # Get number of tokens for the article\n",
    "                num_tokens = MDE.num_tokens_from_string(article.additional_data[\"text_body\"], \"cl100k_base\")\n",
    "                if num_tokens > MDE.article_token_threshold:\n",
    "                    logger.info(f'Article Length: {num_tokens} tokens, using article summary instead')\n",
    "                    result = MDE.eventDetails.run(article=article.summary, feedback=feedback)\n",
    "                else:\n",
    "                    result = MDE.eventDetails.run(article=article.additional_data[\"text_body\"], feedback=feedback)\n",
    "                # Validate the output\n",
    "                validation_results = outputValidator.validate(MDE.eventDetails, result)\n",
    "                if not validation_results[0]:\n",
    "                    raise Exception(validation_results[1])\n",
    "\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Error: Event Details Extraction Failed -> {e}\") from e\n",
    "\n",
    "            logger.info(f'Successfully extracted disruption Event Details: {result}')\n",
    "            return result\n",
    "    \n",
    "        @staticmethod\n",
    "        def articleAddParams(article: Article, params:dict) -> Article:\n",
    "            \"\"\"Adds the given params to Article.additional_data object\"\"\"\n",
    "            # Add the params to the article dictionary\n",
    "            article.additional_data.update(params)\n",
    "            logger.info(f'Added number of params: {len(params)}')\n",
    "            return article\n",
    "    \n",
    "        @staticmethod\n",
    "        def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
    "            \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "            encoding = tiktoken.get_encoding(encoding_name)\n",
    "            num_tokens = len(encoding.encode(string))\n",
    "            return num_tokens\n",
    "\n",
    "        @classmethod\n",
    "        def _process(cls, article: Article, url: str = None) -> Article:\n",
    "            \"\"\"Given an article or a url, use the LLMChains to extract the disruption event information\"\"\"\n",
    "            try:\n",
    "                if url:\n",
    "                    # Extract the article from the url as a newspaper3k Article object\n",
    "                    article = cls._articleExtraction(url)\n",
    "\n",
    "                # Check if the article is a disruption event article\n",
    "                if not cls._binaryClassifier(article):\n",
    "                    raise Exception(\"Error: Article is not a disruption event article\")\n",
    "            \n",
    "                # Extract the location of the disruption event\n",
    "                location = cls._locationExtractor(article, feedback=\"\")\n",
    "                logger.info(f'Location extracted: {location}')\n",
    "                coordinates_info = cls.get_coordinates(location)\n",
    "                logger.info(f'Coordinates info: {coordinates_info}')\n",
    "                # Loop until the coordinates are valid\n",
    "                max_retries = 3\n",
    "                retries = 0\n",
    "                while isinstance(coordinates, str) and retries < max_retries:\n",
    "                    logger.info(f'Location is not valid, please try again. Location: {location} coordinates: {coordinates_info}')\n",
    "                    location = cls._locationExtractor(article, feedback=coordinates_info)\n",
    "                    coordinates_info = cls.get_coordinates(location)\n",
    "                    retries += 1\n",
    "\n",
    "                # Extract the disruption event information\n",
    "                event_details = cls._eventDetails(article, feedback=\"\")\n",
    "\n",
    "                article = cls.articleAddParams(article, {\"location\": location, \"coordinates\": coordinates_info})\n",
    "                article = cls.articleAddParams(article, event_details)\n",
    "                return article\n",
    "        \n",
    "            except Exception as e:\n",
    "                logger.error(e)\n",
    "                return str(e)\n",
    "\n",
    "        @classmethod\n",
    "        def processUrl(cls, url: str) -> Article:\n",
    "            \"\"\"Given a url, use the LLMChains to extract the disruption event information\"\"\"\n",
    "            return cls._process(None, url)\n",
    "\n",
    "        @classmethod\n",
    "        def process(cls, article: Article) -> Article:\n",
    "            \"\"\"Main processing function, given an article, use the LLMChains to extract the disruption event information\"\"\"\n",
    "            return cls._process(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 15:09:53,590:INFO - Article Length: 1710 tokens, using article summary instead\n",
      "2023-09-11 15:09:56,842:INFO - Successfully classified isDisruptionEventarticle: True\n",
      "2023-09-11 15:09:56,860:INFO - Article Length: 1710 tokens, using article summary instead\n",
      "2023-09-11 15:09:58,159:INFO - Successfully extracted disruption location: Keaton Beach, Florida, USA\n",
      "2023-09-11 15:09:58,164:INFO - Location extracted: Keaton Beach, Florida, USA\n",
      "2023-09-11 15:09:59,037:INFO - Coordinates info: (29.8252983, -83.5938806)\n",
      "2023-09-11 15:09:59,041:INFO - Article Length: 1710 tokens, using article summary instead\n",
      "2023-09-11 15:10:02,552:INFO - Successfully extracted disruption Event Details: {'name': 'Hurricane Idalia', 'disruptionType': 'Hurricane', 'severity': 'Category 3', 'date': 'YYYY-MM-DD', 'radius': 0}\n",
      "2023-09-11 15:10:02,554:INFO - Added number of params: 2\n",
      "2023-09-11 15:10:02,556:INFO - Added number of params: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<newspaper.article.Article object at 0x00000227187228C0>\n"
     ]
    }
   ],
   "source": [
    "# Process a URL to extract disruption event information\n",
    "final_article = MDE.processUrl(url = \"https://www.usnews.com/news/us/articles/2023-08-30/idalia-predicted-to-hit-florida-as-category-4-hurricane-with-catastrophic-storm-surge\")\n",
    "\n",
    "# Print the extracted information\n",
    "print(final_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Supabase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInsertor:\n",
    "    \"\"\"\n",
    "    TLDR: \"Fancy INSERT INTO statement for the supabase\" (Need to migrate over)\n",
    "\n",
    "    Methods:\n",
    "        * addDisruptionEvent(self, DisruptionEvent: dict)\n",
    "        * addEventDataRelation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, supabase: Client):\n",
    "        self.supabase = supabase\n",
    "\n",
    "\n",
    "    def addArticleData(self, article:Article):\n",
    "        article_dict = self._formatArticleDict(article)\n",
    "        try:\n",
    "            data, count = self._insertArticleData(article_dict)\n",
    "            id = self._extractArticleId(data)\n",
    "            article_dict['id'] = id\n",
    "            return article_dict\n",
    "        except postgrest.exceptions.APIError as e:\n",
    "            self._handleInsertError(e, article_dict)\n",
    "\n",
    "    def _formatArticleDict(self, article:Article):\n",
    "        return {\n",
    "            \"Title\": article.title,\n",
    "            \"Text\": article.text,\n",
    "            \"Location\": article.additional_data[\"location\"],\n",
    "            \"lat\": article.additional_data[\"coordinates\"][0],\n",
    "            \"lng\": article.additional_data[\"coordinates\"][1],\n",
    "            \"DisruptionType\": article.additional_data[\"disruptionType\"],\n",
    "            \"Severity\": article.additional_data[\"severity\"],\n",
    "            \"SourceName\": article.source_url,\n",
    "            \"Url\": article.url,\n",
    "            \"ImageUrl\": article.top_image,\n",
    "            # \"PublishedDate\": article.publish_date,\n",
    "            \"Radius\": article.additional_data[\"radius\"]*1000, # Convert to meters\n",
    "        }\n",
    "\n",
    "    def _insertArticleData(self, article_dict:dict):\n",
    "        return supabase.table(\"Article\").insert(article_dict).execute()\n",
    "\n",
    "    def _extractArticleId(self, data):\n",
    "        return data[1][0]['id']\n",
    "\n",
    "    def _handleInsertError(self, error, article_dict:dict):\n",
    "        print(f'Error inserting into Supabase: {error}')\n",
    "        print(error.code, error.message, error.details)\n",
    "        if error.code == '23505':\n",
    "            print(f'Article with URL {article_dict[\"Url\"]} already exists in the database.')\n",
    "            existing_data = supabase.table(self.table).select('*').eq('Url', article_dict['Url']).execute()\n",
    "            return existing_data.data[0]\n",
    "        else:\n",
    "            print(f'Unexpected error: {error}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
