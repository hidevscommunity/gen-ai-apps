{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os.path\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import openai\n",
    "import wavio as wv\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from utils import get_file_text, get_resume_initial_message, get_jd_initial_message, get_resume_actionable_insights_initial_message, get_user_work_exp\n",
    "from qa_model import generate_response\n",
    "import PyPDF2\n",
    "import os\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('openai_api_key')\n",
    "serpapi_api_key = os.getenv('serpapi_api_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result='''1. Can you tell me about your experience working as a Machine Learning Intern at ITC? How did you use clustering and regression models to optimize the supply chain network?\n",
    "2. Could you explain the projects you worked on as a Data Science Intern at Future Smart AI? How did you use NLP and vector databases in the development of NLP-related products?\n",
    "3. As Chief of Staff of JU Debating Society, what were your responsibilities in conducting debating competitions and workshops?\n",
    "4. Can you tell me about your role as Product Lead at JU Product Club and the development of work.ai, a one-stop solution for hassle-free LinkedIn onboarding?\n",
    "5. Can you explain your project on image classification using soft Attention Voting Ensemble Classifier and transfer learning approaches? How did you achieve an accuracy of 98.58%?\n",
    "6. How did you build a custom transformer for language translation from English to Spanish in your project on machine translation?\n",
    "7. Could you explain how you built a diagnostic model for heart disease classification using BERT and associated patient reports?\n",
    "8. Can you tell me about the chatbot you developed using MySQL, OpenAI, Langchain, ChromaDB, and FastAPI? How does it work and what features does it have?   \n",
    "9. What did you learn in the Machine Learning A-Z: Hands-on Python and R in Data Science certification course? How did you apply those learnings to different datasets?\n",
    "10. Can you tell me about your hobbies, such as playing outdoor games during leisure time and videography/video editing? How do you pursue those interests outside of work?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  TRISHANU DAS         Email id-dastrishanu01@gmail.com  \n",
      "Male, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \n",
      "A motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \n",
      "Education  Institution  Board  %/CGPA  Year  \n",
      "B.E. Production \n",
      "Engineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \n",
      "Class XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \n",
      "Class X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \n",
      "SKILLS  \n",
      "Tools and  \n",
      "Languages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \n",
      "Vector databases.  \n",
      "Proficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \n",
      "ACADEMIC ACHIEVEMENTS  \n",
      "WBJEE   Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \n",
      "IMMO   Gold medalist in International Master Mathematics Olympiad  2016  \n",
      "KIIT-MUN 2022   Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \n",
      "Nations 2022  2021  \n",
      "WORK EXPERIENCE AND INTERNSHIPS  \n",
      "Machine Learning  \n",
      "Intern at ITC \n",
      "   Used machine learning clustering models like K -Means and DBScan and Regression \n",
      "models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \n",
      "to predict freight rates to optimize  the supply chain network at ITC  2022  \n",
      "Data Science intern \n",
      "at Future Smart AI   Responsible for the development of NLP related products using Langchain, OpenAI, \n",
      "Vector Databases,  mySQL  etc. 2023 -present  \n",
      "POSITIONS OF RESPONSIBILITY  \n",
      "Chief of Staff  \n",
      "JU Debating Society   Conducting debating competitions, workshops on a regular basis  \n",
      " Shouldering the Administrative role for JUMUN 202 3 2020 -present  \n",
      "Product Lead  \n",
      "JU Product Club   Head of development of product of work.ai, a one -stop solution for hassle free easy \n",
      "LinkedIn onboarding.  2021  \n",
      "PROJECTS  \n",
      "Image Classification  \n",
      "(Research)   Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \n",
      "approaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \n",
      "(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \n",
      "methods used.  2023  \n",
      "Machine Translation   Built a Custom Transformer for language translation from English to Spanish.  2023  \n",
      "Heart Disease  \n",
      "Classification   Built a diagnostic model based on the associated reports  from the patients using BERT \n",
      "to classify heart diseases.  2023  \n",
      " \n",
      "Chatbot \n",
      "Development   Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \n",
      "FastAPI.  2023  \n",
      "CERTIFICATIONS  \n",
      "Machine Learning \n",
      "A-Z: Hands on \n",
      "Python and R in \n",
      "Data Science   Learnt  about different Machine Learning models and implement ed them  on various \n",
      "datasets  2022  \n",
      "HOBBIES  \n",
      "Sports   Playing outdoor games during leisure time  \n",
      "Videography and \n",
      "Video Editing   Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"E:\\Documents\\CV\\Curriculum vitae_Trishanu Das OpenCV.pdf\"\n",
    "content = \"\"\n",
    "# Open the PDF file\n",
    "with open(pdf_path, \"rb\") as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    # Get the number of pages in the PDF\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        page = pdf_reader.pages[i]\n",
    "        content += page.extract_text()\n",
    "\n",
    "print(\"Content: \", content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRISHANU DAS         Email id-dastrishanu01@gmail.com  \\nMale, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \\nA motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \\nEducation  Institution  Board  %/CGPA  Year  \\nB.E. Production \\nEngineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \\nClass XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \\nClass X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \\nSKILLS  \\nTools and  \\nLanguages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \\nVector databases.  \\nProficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \\nACADEMIC ACHIEVEMENTS  \\nWBJEE  \\uf0b7 Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \\nIMMO  \\uf0b7 Gold medalist in International Master Mathematics Olympiad  2016  \\nKIIT-MUN 2022  \\uf0b7 Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \\nNations 2022  2021  \\nWORK EXPERIENCE AND INTERNSHIPS  \\nMachine Learning  \\nIntern at ITC \\n \\uf0b7  Used machine learning clustering models like K -Means and DBScan and Regression \\nmodels like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \\nto predict freight rates to optimize  the supply chain network at ITC  2022  \\nData Science intern \\nat Future Smart AI  \\uf0b7 Responsible for the development of NLP related products using Langchain, OpenAI, \\nVector Databases,  mySQL  etc. 2023 -present  \\nPOSITIONS OF RESPONSIBILITY  \\nChief of Staff  \\nJU Debating Society  \\uf0b7 Conducting debating competitions, workshops on a regular basis  \\n\\uf0b7 Shouldering the Administrative role for JUMUN 202 3 2020 -present  \\nProduct Lead  \\nJU Product Club  \\uf0b7 Head of development of product of work.ai, a one -stop solution for hassle free easy \\nLinkedIn onboarding.  2021  \\nPROJECTS  \\nImage Classification  \\n(Research)  \\uf0b7 Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \\napproaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \\n(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \\nmethods used.  2023  \\nMachine Translation  \\uf0b7 Built a Custom Transformer for language translation from English to Spanish.  2023  \\nHeart Disease  \\nClassification  \\uf0b7 Built a diagnostic model based on the associated reports  from the patients using BERT \\nto classify heart diseases.  2023  \\n \\nChatbot \\nDevelopment  \\uf0b7 Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \\nFastAPI.  2023  \\nCERTIFICATIONS  \\nMachine Learning \\nA-Z: Hands on \\nPython and R in \\nData Science  \\uf0b7 Learnt  about different Machine Learning models and implement ed them  on various \\ndatasets  2022  \\nHOBBIES  \\nSports  \\uf0b7 Playing outdoor games during leisure time  \\nVideography and \\nVideo Editing  \\uf0b7 Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \\n '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Document(page_content=content)\n",
    "data.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(page_content='TRISHANU DAS         Email id-dastrishanu01@gmail.com  \\nMale, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \\nA motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \\nEducation  Institution  Board  %/CGPA  Year  \\nB.E. Production \\nEngineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \\nClass XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \\nClass X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \\nSKILLS  \\nTools and  \\nLanguages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \\nVector databases.  \\nProficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \\nACADEMIC ACHIEVEMENTS  \\nWBJEE  \\uf0b7 Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \\nIMMO  \\uf0b7 Gold medalist in International Master Mathematics Olympiad  2016  \\nKIIT-MUN 2022  \\uf0b7 Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \\nNations 2022  2021  \\nWORK EXPERIENCE AND INTERNSHIPS  \\nMachine Learning  \\nIntern at ITC \\n \\uf0b7  Used machine learning clustering models like K -Means and DBScan and Regression \\nmodels like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \\nto predict freight rates to optimize  the supply chain network at ITC  2022  \\nData Science intern \\nat Future Smart AI  \\uf0b7 Responsible for the development of NLP related products using Langchain, OpenAI, \\nVector Databases,  mySQL  etc. 2023 -present  \\nPOSITIONS OF RESPONSIBILITY  \\nChief of Staff  \\nJU Debating Society  \\uf0b7 Conducting debating competitions, workshops on a regular basis  \\n\\uf0b7 Shouldering the Administrative role for JUMUN 202 3 2020 -present  \\nProduct Lead  \\nJU Product Club  \\uf0b7 Head of development of product of work.ai, a one -stop solution for hassle free easy \\nLinkedIn onboarding.  2021  \\nPROJECTS  \\nImage Classification  \\n(Research)  \\uf0b7 Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \\napproaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \\n(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \\nmethods used.  2023  \\nMachine Translation  \\uf0b7 Built a Custom Transformer for language translation from English to Spanish.  2023  \\nHeart Disease  \\nClassification  \\uf0b7 Built a diagnostic model based on the associated reports  from the patients using BERT \\nto classify heart diseases.  2023  \\n \\nChatbot \\nDevelopment  \\uf0b7 Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \\nFastAPI.  2023  \\nCERTIFICATIONS  \\nMachine Learning \\nA-Z: Hands on \\nPython and R in \\nData Science  \\uf0b7 Learnt  about different Machine Learning models and implement ed them  on various \\ndatasets  2022  \\nHOBBIES  \\nSports  \\uf0b7 Playing outdoor games during leisure time  \\nVideography and \\nVideo Editing  \\uf0b7 Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \\n ', metadata={})\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = get_resume_initial_message(text)\n",
    "# res = generate_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\"Based on the candidate's skills, experience, and qualifications, here are some potential interview questions:\", '', '1. Can you provide an example of a project where you used machine learning clustering models like K-Means and DBScan to optimize the supply chain network? (ITC Internship)', '2. How did you apply NLP techniques using Langchain, OpenAI, and Vector Databases in the development of NLP-related products at Future Smart AI?', '3. Can you explain how you utilized soft Attention and Transfer Learning in your research project to detect defects in Selective Laser Sintering bed images? (Image Classification)', '4. Tell us about the diagnostic model you built using BERT to classify heart diseases. How did you train the model and what were the results?', '5. Describe your experience in developing a conversational chatbot using MySQL, OpenAI, Langchain, ChromaDB, and FastAPI.', '6. How do you apply problem-solving skills when faced with challenges in your projects?', '7. Can you provide an example of a time when you demonstrated effective team management skills while working on a project?', '8. How do you stay updated with the latest developments in the field of computer vision and NLP?', '9. What is the most challenging project you have worked on, and how did you overcome the challenges?', '10. How do you contribute to the success of a debating society as the Chief of Staff?', '11. Can you explain your role as the Product Lead in the development of work.ai? What were the challenges you faced and how did you address them?', '12. How did you apply your communication skills in conducting debating competitions and workshops as the Chief of Staff of JU Debating Society?', '13. What motivated you to participate in the WBJEE and how did you prepare for it?', '14. How did you acquire your proficiency in computer vision and NLP? Are there any specific projects or courses that helped you gain expertise in these areas?', '15. Can you provide an example of a time when you used your problem-solving skills to overcome a technical challenge during a project?', '', \"Note: It is important to avoid asking about the candidate's age, gender, hobbies, or personal information as these are not relevant to the job interview.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Can you tell me about your experience with machine learning clustering models like K-Means and DBScan? How did you utilize these models to optimize the supply chain network at ITC during your internship?\n",
      "\n",
      "2. In your internship at Future Smart AI, what NLP-related products did you develop using Langchain, OpenAI, Vector Databases, and MySQL? \n",
      "\n",
      "3. As an intern at ITC, how did you use regression models like Ridge, Lasso, Decision Trees, Random Forest Trees, and Boosting algorithms to predict freight rates and optimize the supply chain network?\n",
      "\n",
      "4. Could you explain your role as Chief of Staff in the JU Debating Society? How did you organize debating competitions and workshops? \n",
      "\n",
      "5. As the Product Lead at JU Product Club, how did you contribute to the development of work.ai, the onboarding solution for LinkedIn? \n",
      "\n",
      "6. Can you elaborate on your research project on Image Classification? How did you use soft Attention Voting Ensemble Classifier and Transfer learning approaches to detect defects in SLS bed images? \n",
      "\n",
      "7. Tell me about the diagnostic model you built for heart disease classification using BERT. What were the key features or inputs you considered? \n",
      "\n",
      "8. Describe the conversational chatbot you developed using MySQL, OpenAI, Langchain, ChromaDB, and FastAPI. How did you ensure a smooth conversation flow and accurate responses? \n",
      "\n",
      "9. What did you learn from the Machine Learning A-Z certification course? Can you give an example of a dataset you worked with and the models you implemented? \n",
      "\n",
      "10. Outside of your academic and professional life, can you tell me more about your hobbies like playing sports and videography/video editing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the text into a list of points\n",
    "points = res.strip().split('\\n')\n",
    "\n",
    "# Print each point in the list\n",
    "for i, point in enumerate(points, start=3):\n",
    "    print(f\"{point}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Yes.\n",
      "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3mDaniil Medvedev\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFollow up: What is the hometown of Daniil Medvedev?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3mWhat is Daniil Medvedev's nationality? Daniil Medvedev is Russian. He was born on February 11, 1996, in Moscow, Russia. Who are Medvedev's parents? Daniil ...\u001b[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse output: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m      7\u001b[0m tools \u001b[39m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     Tool(\n\u001b[0;32m      9\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIntermediate Answer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m ]\n\u001b[0;32m     15\u001b[0m self_ask_with_search \u001b[39m=\u001b[39m initialize_agent(\n\u001b[0;32m     16\u001b[0m     tools, llm, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mSELF_ASK_WITH_SEARCH, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 18\u001b[0m self_ask_with_search\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m     19\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mWhat is the hometown of the reigning men\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms U.S. Open champion?\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     20\u001b[0m )\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\chains\\base.py:475\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    474\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 475\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    476\u001b[0m         _output_key\n\u001b[0;32m    477\u001b[0m     ]\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    481\u001b[0m         _output_key\n\u001b[0;32m    482\u001b[0m     ]\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\chains\\base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    283\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    284\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\chains\\base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    270\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    271\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m )\n\u001b[0;32m    274\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    277\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    278\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    281\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\agents\\agent.py:1036\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1036\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1037\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1038\u001b[0m         color_mapping,\n\u001b[0;32m   1039\u001b[0m         inputs,\n\u001b[0;32m   1040\u001b[0m         intermediate_steps,\n\u001b[0;32m   1041\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1042\u001b[0m     )\n\u001b[0;32m   1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1045\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1046\u001b[0m         )\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\agents\\agent.py:844\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    842\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 844\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    845\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\agents\\agent.py:833\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    830\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m    832\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 833\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mplan(\n\u001b[0;32m    834\u001b[0m         intermediate_steps,\n\u001b[0;32m    835\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    836\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[0;32m    837\u001b[0m     )\n\u001b[0;32m    838\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    839\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\agents\\agent.py:457\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    456\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 457\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\agents\\self_ask_with_search\\output_parser.py:17\u001b[0m, in \u001b[0;36mSelfAskOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m([follow \u001b[39min\u001b[39;00m last_line \u001b[39mfor\u001b[39;00m follow \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollowups]):\n\u001b[0;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinish_string \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m last_line:\n\u001b[1;32m---> 17\u001b[0m         \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse output: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m AgentFinish({\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m: last_line[\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinish_string) :]}, text)\n\u001b[0;32m     20\u001b[0m after_colon \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse output: "
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(\n",
    "    tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True\n",
    ")\n",
    "self_ask_with_search.run(\n",
    "    \"What is the hometown of the reigning men's U.S. Open champion?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "# Now we can override it and set it to \"AI Assistant\"\n",
    "\n",
    "template = \"\"\"Ask meaningful and relatable follow up questions to the user based on the context that the user provides.\n",
    "Ask questions related to that context, be precise.\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"AI Assistant\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='Ask meaningful and relatable follow up questions to the user based on the context that the user provides.\\nAsk questions related to that context, be precise.\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI Assistant:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAsk meaningful and relatable follow up questions to the user based on the context that the user provides.\n",
      "Ask questions related to that context, be precise.\n",
      "Current conversation:\n",
      "\n",
      "Human: Kolkata (formerly Calcutta) is the capital of India's West Bengal state. Founded as an East India Company trading post, it was India's capital under the British Raj from 1773–1911.\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "context = \"Kolkata (formerly Calcutta) is the capital of India's West Bengal state. Founded as an East India Company trading post, it was India's capital under the British Raj from 1773–1911.\"\n",
    "res = conversation.predict(input=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's interesting! Have you ever been to Kolkata?\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAsk meaningful and relatable follow up questions to the user based on the context that the user provides.\n",
      "Ask questions related to that context, be precise.\n",
      "Current conversation:\n",
      "Human: Kolkata (formerly Calcutta) is the capital of India's West Bengal state. Founded as an East India Company trading post, it was India's capital under the British Raj from 1773–1911.\n",
      "AI Assistant: That's interesting! Have you ever been to Kolkata?\n",
      "Human: Delhi, India’s capital territory, is a massive metropolitan area in the country’s north. In Old Delhi, a neighborhood dating to the 1600s, stands the imposing Mughal-era Red Fort, a symbol of India, and the sprawling Jama Masjid mosque, whose courtyard accommodates 25,000 people.\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That sounds fascinating! Have you had the chance to visit the Red Fort or Jama Masjid mosque in Delhi?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Delhi, India’s capital territory, is a massive metropolitan area in the country’s north. In Old Delhi, a neighborhood dating to the 1600s, stands the imposing Mughal-era Red Fort, a symbol of India, and the sprawling Jama Masjid mosque, whose courtyard accommodates 25,000 people.\"\n",
    "conversation.predict(input=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAsk meaningful and relatable questions to the user based on the context that the user provides.\n",
      "Ask questions related to that context, be precise.\n",
      "Current conversation:\n",
      "Human: Kolkata (formerly Calcutta) is the capital of India's West Bengal state. Founded as an East India Company trading post, it was India's capital under the British Raj from 1773–1911.\n",
      "AI Assistant: Have you ever been to Kolkata?\n",
      "Human: Delhi, India’s capital territory, is a massive metropolitan area in the country’s north. In Old Delhi, a neighborhood dating to the 1600s, stands the imposing Mughal-era Red Fort, a symbol of India, and the sprawling Jama Masjid mosque, whose courtyard accommodates 25,000 people.\n",
      "AI Assistant: Have you ever visited the Red Fort in Delhi?\n",
      "Human: Mumbai (formerly called Bombay) is a densely populated city on India’s west coast. A financial center, it's India's largest city. On the Mumbai Harbour waterfront stands the iconic Gateway of India stone arch, built by the British Raj in 1924. Offshore, nearby Elephanta Island holds ancient cave temples dedicated to the Hindu god Shiva. The city's also famous as the heart of the Bollywood film industry.\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Have you ever been to Elephanta Island and explored its ancient cave temples?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Mumbai (formerly called Bombay) is a densely populated city on India’s west coast. A financial center, it's India's largest city. On the Mumbai Harbour waterfront stands the iconic Gateway of India stone arch, built by the British Raj in 1924. Offshore, nearby Elephanta Island holds ancient cave temples dedicated to the Hindu god Shiva. The city's also famous as the heart of the Bollywood film industry.\"\n",
    "conversation.predict(input=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "template = \"\"\"You are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(k=2,memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "chain = load_qa_chain(\n",
    "    llm=llm, chain_type=\"stuff\", memory=memory, prompt=prompt, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Chain.run of StuffDocumentsChain(memory=ConversationBufferWindowMemory(chat_memory=ChatMessageHistory(messages=[]), output_key=None, input_key='human_input', return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='chat_history', k=2), callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, input_key='input_documents', output_key='output_text', llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['chat_history', 'human_input', 'context'], output_parser=None, partial_variables={}, template='You are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\\n\\n{context}\\n\\n{chat_history}\\nHuman: {human_input}\\nChatbot:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=StrOutputParser(), return_final_only=True, llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], output_parser=None, partial_variables={}, template='{page_content}', template_format='f-string', validate_template=True), document_variable_name='context', document_separator='\\n\\n')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
      "\n",
      "TRISHANU DAS         Email id-dastrishanu01@gmail.com  \n",
      "Male, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \n",
      "A motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \n",
      "Education  Institution  Board  %/CGPA  Year  \n",
      "B.E. Production \n",
      "Engineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \n",
      "Class XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \n",
      "Class X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \n",
      "SKILLS  \n",
      "Tools and  \n",
      "Languages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \n",
      "Vector databases.  \n",
      "Proficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \n",
      "ACADEMIC ACHIEVEMENTS  \n",
      "WBJEE   Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \n",
      "IMMO   Gold medalist in International Master Mathematics Olympiad  2016  \n",
      "KIIT-MUN 2022   Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \n",
      "Nations 2022  2021  \n",
      "WORK EXPERIENCE AND INTERNSHIPS  \n",
      "Machine Learning  \n",
      "Intern at ITC \n",
      "   Used machine learning clustering models like K -Means and DBScan and Regression \n",
      "models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \n",
      "to predict freight rates to optimize  the supply chain network at ITC  2022  \n",
      "Data Science intern \n",
      "at Future Smart AI   Responsible for the development of NLP related products using Langchain, OpenAI, \n",
      "Vector Databases,  mySQL  etc. 2023 -present  \n",
      "POSITIONS OF RESPONSIBILITY  \n",
      "Chief of Staff  \n",
      "JU Debating Society   Conducting debating competitions, workshops on a regular basis  \n",
      " Shouldering the Administrative role for JUMUN 202 3 2020 -present  \n",
      "Product Lead  \n",
      "JU Product Club   Head of development of product of work.ai, a one -stop solution for hassle free easy \n",
      "LinkedIn onboarding.  2021  \n",
      "PROJECTS  \n",
      "Image Classification  \n",
      "(Research)   Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \n",
      "approaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \n",
      "(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \n",
      "methods used.  2023  \n",
      "Machine Translation   Built a Custom Transformer for language translation from English to Spanish.  2023  \n",
      "Heart Disease  \n",
      "Classification   Built a diagnostic model based on the associated reports  from the patients using BERT \n",
      "to classify heart diseases.  2023  \n",
      " \n",
      "Chatbot \n",
      "Development   Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \n",
      "FastAPI.  2023  \n",
      "CERTIFICATIONS  \n",
      "Machine Learning \n",
      "A-Z: Hands on \n",
      "Python and R in \n",
      "Data Science   Learnt  about different Machine Learning models and implement ed them  on various \n",
      "datasets  2022  \n",
      "HOBBIES  \n",
      "Sports   Playing outdoor games during leisure time  \n",
      "Videography and \n",
      "Video Editing   Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \n",
      " \n",
      "\n",
      "\n",
      "Human: Hello\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Hello! Thank you for joining the interview. Can you please tell me more about your experience with machine learning clustering models and regression models?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hello\"\n",
    "chain({\"input_documents\": [data], \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
      "\n",
      "TRISHANU DAS         Email id-dastrishanu01@gmail.com  \n",
      "Male, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \n",
      "A motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \n",
      "Education  Institution  Board  %/CGPA  Year  \n",
      "B.E. Production \n",
      "Engineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \n",
      "Class XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \n",
      "Class X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \n",
      "SKILLS  \n",
      "Tools and  \n",
      "Languages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \n",
      "Vector databases.  \n",
      "Proficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \n",
      "ACADEMIC ACHIEVEMENTS  \n",
      "WBJEE   Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \n",
      "IMMO   Gold medalist in International Master Mathematics Olympiad  2016  \n",
      "KIIT-MUN 2022   Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \n",
      "Nations 2022  2021  \n",
      "WORK EXPERIENCE AND INTERNSHIPS  \n",
      "Machine Learning  \n",
      "Intern at ITC \n",
      "   Used machine learning clustering models like K -Means and DBScan and Regression \n",
      "models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \n",
      "to predict freight rates to optimize  the supply chain network at ITC  2022  \n",
      "Data Science intern \n",
      "at Future Smart AI   Responsible for the development of NLP related products using Langchain, OpenAI, \n",
      "Vector Databases,  mySQL  etc. 2023 -present  \n",
      "POSITIONS OF RESPONSIBILITY  \n",
      "Chief of Staff  \n",
      "JU Debating Society   Conducting debating competitions, workshops on a regular basis  \n",
      " Shouldering the Administrative role for JUMUN 202 3 2020 -present  \n",
      "Product Lead  \n",
      "JU Product Club   Head of development of product of work.ai, a one -stop solution for hassle free easy \n",
      "LinkedIn onboarding.  2021  \n",
      "PROJECTS  \n",
      "Image Classification  \n",
      "(Research)   Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \n",
      "approaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \n",
      "(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \n",
      "methods used.  2023  \n",
      "Machine Translation   Built a Custom Transformer for language translation from English to Spanish.  2023  \n",
      "Heart Disease  \n",
      "Classification   Built a diagnostic model based on the associated reports  from the patients using BERT \n",
      "to classify heart diseases.  2023  \n",
      " \n",
      "Chatbot \n",
      "Development   Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \n",
      "FastAPI.  2023  \n",
      "CERTIFICATIONS  \n",
      "Machine Learning \n",
      "A-Z: Hands on \n",
      "Python and R in \n",
      "Data Science   Learnt  about different Machine Learning models and implement ed them  on various \n",
      "datasets  2022  \n",
      "HOBBIES  \n",
      "Sports   Playing outdoor games during leisure time  \n",
      "Videography and \n",
      "Video Editing   Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \n",
      " \n",
      "\n",
      "Human: I have worked with random forests, decision trees, and logistic regression. I have also worked with sql databases\n",
      "AI: That's great to hear! Could you provide some examples of how you have used these machine learning models and SQL databases in your previous projects or internships?\n",
      "Human: I have worked with random forests, decision trees, and logistic regression. I have also worked with sql databases\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': \"That's great to hear! Could you provide some examples of how you have used these machine learning models and SQL databases in your previous projects or internships?\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I have worked with random forests, decision trees, and logistic regression. I have also worked with sql databases\"\n",
    "chain({\"input_documents\": [data], \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
      "\n",
      "TRISHANU DAS         Email id-dastrishanu01@gmail.com  \n",
      "Male, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \n",
      "A motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \n",
      "Education  Institution  Board  %/CGPA  Year  \n",
      "B.E. Production \n",
      "Engineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \n",
      "Class XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \n",
      "Class X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \n",
      "SKILLS  \n",
      "Tools and  \n",
      "Languages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \n",
      "Vector databases.  \n",
      "Proficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \n",
      "ACADEMIC ACHIEVEMENTS  \n",
      "WBJEE   Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \n",
      "IMMO   Gold medalist in International Master Mathematics Olympiad  2016  \n",
      "KIIT-MUN 2022   Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \n",
      "Nations 2022  2021  \n",
      "WORK EXPERIENCE AND INTERNSHIPS  \n",
      "Machine Learning  \n",
      "Intern at ITC \n",
      "   Used machine learning clustering models like K -Means and DBScan and Regression \n",
      "models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \n",
      "to predict freight rates to optimize  the supply chain network at ITC  2022  \n",
      "Data Science intern \n",
      "at Future Smart AI   Responsible for the development of NLP related products using Langchain, OpenAI, \n",
      "Vector Databases,  mySQL  etc. 2023 -present  \n",
      "POSITIONS OF RESPONSIBILITY  \n",
      "Chief of Staff  \n",
      "JU Debating Society   Conducting debating competitions, workshops on a regular basis  \n",
      " Shouldering the Administrative role for JUMUN 202 3 2020 -present  \n",
      "Product Lead  \n",
      "JU Product Club   Head of development of product of work.ai, a one -stop solution for hassle free easy \n",
      "LinkedIn onboarding.  2021  \n",
      "PROJECTS  \n",
      "Image Classification  \n",
      "(Research)   Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \n",
      "approaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \n",
      "(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \n",
      "methods used.  2023  \n",
      "Machine Translation   Built a Custom Transformer for language translation from English to Spanish.  2023  \n",
      "Heart Disease  \n",
      "Classification   Built a diagnostic model based on the associated reports  from the patients using BERT \n",
      "to classify heart diseases.  2023  \n",
      " \n",
      "Chatbot \n",
      "Development   Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \n",
      "FastAPI.  2023  \n",
      "CERTIFICATIONS  \n",
      "Machine Learning \n",
      "A-Z: Hands on \n",
      "Python and R in \n",
      "Data Science   Learnt  about different Machine Learning models and implement ed them  on various \n",
      "datasets  2022  \n",
      "HOBBIES  \n",
      "Sports   Playing outdoor games during leisure time  \n",
      "Videography and \n",
      "Video Editing   Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \n",
      " \n",
      "\n",
      "Human: I have worked with random forests, decision trees, and logistic regression. I have also worked with sql databases\n",
      "AI: That's great to hear! Could you provide some examples of how you have used these machine learning models and SQL databases in your previous projects or internships?\n",
      "Human: I have worked at ITC and Future Smart AI using these technoologies\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Can you please provide more details about the specific projects or tasks you worked on at ITC and Future Smart AI where you utilized random forests, decision trees, logistic regression, and SQL databases?'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I have worked at ITC and Future Smart AI using these technoologies\"\n",
    "chain({\"input_documents\": [data], \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
      "\n",
      "TRISHANU DAS         Email id-dastrishanu01@gmail.com  \n",
      "Male, Age:20             LinkedIn - linkedin.com/in/trishanu -das-4b603620b  \n",
      "A motivated,  honest and a  passionate individual who is keen on exploring various fields and strives for excellence.  \n",
      "Education  Institution  Board  %/CGPA  Year  \n",
      "B.E. Production \n",
      "Engineering  Jadavpur University  Jadavpur University  8.71/10 (till 5th semester)  2024  \n",
      "Class XII  Sri Aurobindo Institute of Education  ISC 93.7 5% 2020  \n",
      "Class X  Sri Aurobindo Institute of Education  ICSE  94.8%  2018  \n",
      "SKILLS  \n",
      "Tools and  \n",
      "Languages  Python,  NumPy, Pandas, Scikit -Learn , TensorFlow , PyTorch , Selenium, MySQL, FastAPI , Langchain , OpenAI, \n",
      "Vector databases.  \n",
      "Proficiency  Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management  \n",
      "ACADEMIC ACHIEVEMENTS  \n",
      "WBJEE   Secured a rank of 1435 among a pool of 10000 0 applicants  2020  \n",
      "IMMO   Gold medalist in International Master Mathematics Olympiad  2016  \n",
      "KIIT-MUN 2022   Was awarded the prize of” Honorable  Mention” at KIIT International e -Model United \n",
      "Nations 2022  2021  \n",
      "WORK EXPERIENCE AND INTERNSHIPS  \n",
      "Machine Learning  \n",
      "Intern at ITC \n",
      "   Used machine learning clustering models like K -Means and DBScan and Regression \n",
      "models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms \n",
      "to predict freight rates to optimize  the supply chain network at ITC  2022  \n",
      "Data Science intern \n",
      "at Future Smart AI   Responsible for the development of NLP related products using Langchain, OpenAI, \n",
      "Vector Databases,  mySQL  etc. 2023 -present  \n",
      "POSITIONS OF RESPONSIBILITY  \n",
      "Chief of Staff  \n",
      "JU Debating Society   Conducting debating competitions, workshops on a regular basis  \n",
      " Shouldering the Administrative role for JUMUN 202 3 2020 -present  \n",
      "Product Lead  \n",
      "JU Product Club   Head of development of product of work.ai, a one -stop solution for hassle free easy \n",
      "LinkedIn onboarding.  2021  \n",
      "PROJECTS  \n",
      "Image Classification  \n",
      "(Research)   Applied soft Attention soft  Voting Ensemble Classifier along with Transfer learning \n",
      "approaches using VGG19  and ResNet50 to detect defects in Selective Laser Sintering \n",
      "(SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing \n",
      "methods used.  2023  \n",
      "Machine Translation   Built a Custom Transformer for language translation from English to Spanish.  2023  \n",
      "Heart Disease  \n",
      "Classification   Built a diagnostic model based on the associated reports  from the patients using BERT \n",
      "to classify heart diseases.  2023  \n",
      " \n",
      "Chatbot \n",
      "Development   Bulit  a conversational chatbot  using MySQL, OpenAI, Langchain, ChromaDB  and \n",
      "FastAPI.  2023  \n",
      "CERTIFICATIONS  \n",
      "Machine Learning \n",
      "A-Z: Hands on \n",
      "Python and R in \n",
      "Data Science   Learnt  about different Machine Learning models and implement ed them  on various \n",
      "datasets  2022  \n",
      "HOBBIES  \n",
      "Sports   Playing outdoor games during leisure time  \n",
      "Videography and \n",
      "Video Editing   Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects  \n",
      " \n",
      "\n",
      "Human: I have worked at ITC and Future Smart AI using these technoologies\n",
      "AI: Can you please provide more details about the specific projects or tasks you worked on at ITC and Future Smart AI where you utilized random forests, decision trees, logistic regression, and SQL databases?\n",
      "Human: Data Collection and Preprocessing at ITC:\n",
      "\n",
      "Collect historical data related to freight rates, shipment details, routes, distances, fuel prices, and other relevant factors.\n",
      "Preprocess the data, handling missing values, outliers, and performing feature engineering to create meaningful features for the models.\n",
      "Clustering (K-Means, DBScan):\n",
      "\n",
      ".\n",
      "\n",
      "Used SQL to extract data from the database and perform data analysis. at Future-Smat-AI\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Can you please provide more details about the development of the chatbot at Future Smart AI? Specifically, how did you utilize MySQL, OpenAI, Langchain, ChromaDB, and FastAPI in the development process?'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''Data Collection and Preprocessing at ITC:\n",
    "\n",
    "Collect historical data related to freight rates, shipment details, routes, distances, fuel prices, and other relevant factors.\n",
    "Preprocess the data, handling missing values, outliers, and performing feature engineering to create meaningful features for the models.\n",
    "Clustering (K-Means, DBScan):\n",
    "\n",
    ".\n",
    "\n",
    "Used SQL to extract data from the database and perform data analysis. at Future-Smat-AI'''\n",
    "chain({\"input_documents\": [data], \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Can you provide an example of how the chatbot utilized FastAPI and Langchain to enhance its conversational capabilities?'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''the chatbot developed using MySQL, OpenAI, Langchain, ChromaDB, and FastAPI aimed to offer a sophisticated conversational experience by leveraging language understanding, database management, and API integration. \n",
    "This combination of technologies enabled the chatbot to understand user intent, retrieve relevant information, generate human-like responses, and maintain context throughout the conversation.'''\n",
    "chain({\"input_documents\": data, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Data Collection and Preprocessing:\n",
      "\n",
      "Collect historical data related to freight rates, shipment details, routes, distances, fuel prices, and other relevant factors.\n",
      "Preprocess the data, handling missing values, outliers, and performing feature engineering to create meaningful features for the models.\n",
      "Clustering (K-Means, DBScan):\n",
      "\n",
      "Use clustering algorithms like K-Means or DBScan to group similar shipping routes or patterns together.\n",
      "Clusters can help identify regions or routes with similar characteristics, which might lead to similar freight rates.\n",
      "Regression Models (Ridge, Lasso):\n",
      "\n",
      "Utilize linear regression models like Ridge and Lasso to predict freight rates based on features such as distance, cargo type, and transportation mode.\n",
      "Ridge and Lasso can help prevent overfitting by applying regularization to the model.\n",
      "Decision Trees, Random Forests:\n",
      "\n",
      "Decision trees can be used to model the decision-making process for freight rates.\n",
      "Random Forests can combine multiple decision trees to improve predictive accuracy and handle non-linear relationships.\n",
      "AI: That's impressive! Can you tell me more about the chatbot you developed using MySQL, OpenAI, Langchain, ChromaDB, and FastAPI? What was the purpose of the chatbot and how did you integrate these technologies to create a conversational experience?\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(k=1,memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "chain = load_qa_chain(\n",
    "    llm=llm, chain_type=\"stuff\", memory=memory, prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRISHANU DAS\\n\\nEmail id-dastrishanu01@gmail.com\\n\\nLinkedIn- linkedin.com/in/trishanu-das-4b603620b\\n\\nMale, Age:20\\n\\nA motivated, honest and a passionate individual who is keen on exploring various fields and strives for excellence.\\n\\nEducation B.E. Production Engineering\\n\\nInstitution Jadavpur University\\n\\nBoard Jadavpur University\\n\\n%/CGPA Year 8.71/10 (till 5th semester) 2024\\n\\nClass XII\\n\\nSri Aurobindo Institute of Education\\n\\nISC\\n\\n93.75%\\n\\n2020\\n\\nClass X\\n\\nSri Aurobindo Institute of Education\\n\\nICSE\\n\\n94.8%\\n\\n2018\\n\\nSKILLS\\n\\nTools and Languages Proficiency\\n\\nPython, NumPy, Pandas, Scikit-Learn, TensorFlow, PyTorch, Selenium, MySQL, FastAPI, Langchain, OpenAI, Vector databases. Computer Vision, NLP, Communication Skills, Problem Solving, Effective Team Management\\n\\nACADEMIC ACHIEVEMENTS\\n\\nWBJEE\\n\\n2020\\n\\nSecured a rank of 1435 among a pool of 100000 applicants\\n\\nIMMO\\n\\n2016\\n\\nGold medalist in International Master Mathematics Olympiad\\n\\nKIIT-MUN 2022\\n\\n2021\\n\\nWas awarded the prize of” Honorable Mention” at KIIT International e-Model United\\n\\nNations 2022\\n\\nWORK EXPERIENCE AND INTERNSHIPS\\n\\nMachine Learning Intern at ITC\\n\\n2022\\n\\n\\n\\nUsed machine learning clustering models like K-Means and DBScan and Regression models like Ridge, Lasso, Decision Trees, Random Forest Trees and Boosting algorithms to predict freight rates to optimize the supply chain network at ITC\\n\\nData Science intern at Future Smart AI\\n\\n2023-present\\n\\nResponsible for the development of NLP related products using Langchain, OpenAI,\\n\\nVector Databases, mySQL etc.\\n\\nPOSITIONS OF RESPONSIBILITY \\uf0b7 Conducting debating competitions, workshops on a regular basis \\uf0b7 Shouldering the Administrative role for JUMUN 2023 \\uf0b7 Head of development of product of work.ai, a one-stop solution for hassle free easy\\n\\nChief of Staff JU Debating Society Product Lead JU Product Club\\n\\n2020-present\\n\\n2021\\n\\nLinkedIn onboarding.\\n\\nPROJECTS \\uf0b7 Applied soft Attention soft Voting Ensemble Classifier along with Transfer learning\\n\\nImage Classification (Research)\\n\\n2023\\n\\napproaches using VGG19 and ResNet50 to detect defects in Selective Laser Sintering (SLS) bed images to achieve an accuracy of 98.58%, an increase of 5% over existing methods used.\\n\\nMachine Translation \\uf0b7 Built a Custom Transformer for language translation from English to Spanish.\\n\\n2023\\n\\nHeart Disease Classification Chatbot Development\\n\\n2023\\n\\nBuilt a diagnostic model based on the associated reports from the patients using BERT\\n\\nto classify heart diseases.\\n\\n2023\\n\\nBulit a conversational chatbot using MySQL, OpenAI, Langchain, ChromaDB and\\n\\nFastAPI.\\n\\nCERTIFICATIONS Learnt about different Machine Learning models and implemented them on various datasets\\n\\nMachine Learning A-Z: Hands on Python and R in Data Science\\n\\n2022\\n\\n\\n\\nHOBBIES\\n\\nSports\\n\\nPlaying outdoor games during leisure time \\uf0b7 Proficient with video editing tools like Adobe Premiere Pro and Adobe After Effects\\n\\nVideography and Video Editing'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = UnstructuredPDFLoader(pdf_path)\n",
    "data = loader.load()\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Documents\\\\CV\\\\Curriculum vitae_Trishanu Das OpenCV.pdf'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Tool\nfunc\n  Can you provide more details about the development process of the chatbot? is not callable (type=type_error.callable; value=Can you provide more details about the development process of the chatbot?)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 15\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m initialize_agent\n\u001b[0;32m      8\u001b[0m search \u001b[39m=\u001b[39m SerpAPIWrapper()\n\u001b[0;32m      9\u001b[0m tools \u001b[39m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     Tool(\n\u001b[0;32m     11\u001b[0m         name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFollow up questions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m         func\u001b[39m=\u001b[39msearch\u001b[39m.\u001b[39mrun,\n\u001b[0;32m     13\u001b[0m         description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39museful for when you need to ask follow up questions based on the user\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms response\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m     ),\n\u001b[1;32m---> 15\u001b[0m     Tool(\n\u001b[0;32m     16\u001b[0m         name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mContext Retrieval\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     17\u001b[0m         func\u001b[39m=\u001b[39;49mchain\u001b[39m.\u001b[39;49mrun(input_documents\u001b[39m=\u001b[39;49mdata, human_input\u001b[39m=\u001b[39;49mquery),\n\u001b[0;32m     18\u001b[0m         description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mYou are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.use this as the primary source of context information when you are asked the question. Always search for the answers using this tool first, don\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mt make up answers yourself\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     19\u001b[0m     ),\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m ]\n\u001b[0;32m     23\u001b[0m memory \u001b[39m=\u001b[39m ConversationBufferMemory(memory_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchat_history\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m llm \u001b[39m=\u001b[39m ChatOpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\langchain\\tools\\base.py:547\u001b[0m, in \u001b[0;36mTool.__init__\u001b[1;34m(self, name, func, description, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    544\u001b[0m     \u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, func: Callable, description: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m    545\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Initialize tool.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m     \u001b[39msuper\u001b[39m(Tool, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    548\u001b[0m         name\u001b[39m=\u001b[39mname, func\u001b[39m=\u001b[39mfunc, description\u001b[39m=\u001b[39mdescription, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    549\u001b[0m     )\n",
      "File \u001b[1;32me:\\Programs\\Pythonev\\PyTorchenv\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for Tool\nfunc\n  Can you provide more details about the development process of the chatbot? is not callable (type=type_error.callable; value=Can you provide more details about the development process of the chatbot?)"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Follow up questions\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask follow up questions based on the user's response\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Context Retrieval\",\n",
    "        func=chain.run(input_documents=data, human_input=query),\n",
    "        description=\"You are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate.use this as the primary source of context information when you are asked the question. Always search for the answers using this tool first, don't make up answers yourself\"\n",
    "    ),\n",
    "\n",
    "]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_chain\u001b[39m.\u001b[39mrun(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhi\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_chain' is not defined"
     ]
    }
   ],
   "source": [
    "agent_chain.run(input=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Your name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# load document\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "### For multiple documents \n",
    "# loaders = [....]\n",
    "# documents = []\n",
    "# for loader in loaders:\n",
    "#     documents.extend(loader.load())\n",
    "\n",
    "template = \"\"\"You are a hiring manager at a company. You are interviewing a candidate for a job. Ask one meaningful question to the candidate regarding the context and the inputs provided by the candidate. Be formal and precise.\n",
    "\n",
    "{context}\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(k=1,memory_key=\"chat_history\", input_key=\"human_input\")\n",
    "chain = load_qa_chain(\n",
    "    llm=llm, chain_type=\"stuff\", memory=memory, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello, Trishanu. Thank you for your application and for providing your detailed information. I'm interested in learning more about your experience as a Machine Learning Intern at ITC. Can you please tell me more about the specific projects you worked on and the impact they had on optimizing the supply chain network?\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"hello\"\n",
    "chain.run(input_documents=data, human_input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for sharing that information. Can you please provide more details on how you utilized random forests, decision trees, and logistic regression in your projects at ITC? Additionally, can you explain how you incorporated SQL databases into your work?'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I have worked with random forests, decision trees, and logistic regression. I have also worked with sql databases\"\n",
    "chain.run(input_documents=data, human_input=query, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you please provide more details about the project you worked on at ITC where you utilized random forests, decision trees, logistic regression, and incorporated SQL databases?'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hello\"\n",
    "chain({\"input_documents\": data, \"human_input\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Trishanu Das\\nEmail: dastrishanu01@gmail.com\\nLinkedIn: linkedin.com/in/trishanu-das-4b603620b\\nGender: Male\\nAge: 20\\nEducation: B.E. Production Engineering from Jadavpur University\\nAcademic Achievements:\\n- WBJEE 2020: Ranked 1435 out of 100000 applicants\\n- IMMO 2016: Gold medalist in International Master Mathematics Olympiad\\n- KIIT-MUN 2022: Honorable Mention at KIIT International e-Model United Nations 2022\\nWork Experience and Internships:\\n- Machine Learning Intern at ITC in 2022\\n- Data Science Intern at Future Smart AI from 2023 to present\\nPositions of Responsibility:\\n- Chief of Staff at JU Debating Society\\n- Product Lead at JU Product Club\\nProjects:\\n- Image Classification (Research) using soft Attention soft Voting Ensemble Classifier and Transfer learning approaches\\n- Machine Translation from English to Spanish using Custom Transformer\\n- Heart Disease Classification Chatbot Development using BERT\\nCertifications:\\n- Machine Learning A-Z: Hands on Python and R in Data Science in 2022\\nHobbies: Playing outdoor games, videography, and video editing.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"Give me his details\"\n",
    "chain.run(input_documents=data, human_input=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
