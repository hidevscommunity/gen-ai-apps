{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "from IPython.display import Markdown, display\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils import (\n",
    "    get_semantic_scholar_id,\n",
    "    get_pdfs,\n",
    "    load_data,\n",
    "    split_text_to_chunks,\n",
    "    get_paragraphs,\n",
    "    get_titles_abstracts,\n",
    "    get_embeddings,\n",
    "    get_google_results,\n",
    "    generate_answer,\n",
    "    get_tldr,\n",
    "    create_context_chatgpt,\n",
    "    answer_question_chatgpt,\n",
    "    get_semantic_scholar_pdf_id,\n",
    "    controller_id_function,\n",
    "    get_cosine_similarity,\n",
    "    get_paper_info\n",
    ")\n",
    "import openai\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# tqdm pandas progress\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "query = \"do language models plagiarize?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_paper_ids(df):\n",
    "    df[\"paperId\"] = df[\"link\"].apply(controller_id_function)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_paper_info(df):\n",
    "    df[\"paperInfo\"] = df[\"paperId\"].apply(get_paper_info)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_paper_info(df):\n",
    "    df[\"title\"] = df[\"paperInfo\"].apply(lambda x: x[\"title\"])\n",
    "    df[\"abstract\"] = df[\"paperInfo\"].apply(lambda x: x[\"abstract\"])\n",
    "    df[\"venue\"] = df[\"paperInfo\"].apply(lambda x: x[\"venue\"])\n",
    "    df[\"year\"] = df[\"paperInfo\"].apply(lambda x: x[\"year\"])\n",
    "    df[\"openAccessPdf\"] = df[\"paperInfo\"].apply(lambda x: x[\"openAccessPdf\"])\n",
    "    df = df[[\"title\", \"abstract\", \"venue\", \"year\", \"openAccessPdf\", \"paperId\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_pdf_paths(df, folder):\n",
    "    df[\"pdf_paths\"] = df[\"paperId\"].apply(lambda x: folder + x + \".pdf\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_pdfs(df):\n",
    "    print(\"Reading pdfs...\")\n",
    "    df[\"text\"] = df[\"pdf_paths\"].apply(lambda x: load_data(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df[\"paragraphs\"] = df[\"text\"].apply(\n",
    "        lambda x: split_text_to_chunks(x) if not pd.isna(x) else None\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_all_text(df):\n",
    "    paragraphs = get_paragraphs(df)\n",
    "    titles_abstracts = get_titles_abstracts(df)\n",
    "    all_text = paragraphs + titles_abstracts\n",
    "    return all_text\n",
    "\n",
    "\n",
    "def create_text_df(all_text):\n",
    "    df_text = pd.DataFrame(all_text, columns=[\"paperId\", \"text\"])\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def add_embeddings(df_text):\n",
    "    df_text[\"embedding\"] = df_text[\"text\"].apply(lambda x: get_embeddings(x))\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def get_cosine_similarities(df_text, query_embedding):\n",
    "    df_text[\"cosine_similarity\"] = df_text[\"embedding\"].apply(\n",
    "        lambda x: get_cosine_similarity(query_embedding, x)\n",
    "    )\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def sort_by_cosine_similarity(df_text):\n",
    "    df_text = df_text.sort_values(by=[\"cosine_similarity\"], ascending=False)\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def get_top_results(df_text, K):\n",
    "    df_text = df_text.head(K)\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def add_tldrs(df_text):\n",
    "    df_text[\"tldr\"] = df_text[\"text\"].apply(lambda x: get_tldr(x))\n",
    "    return df_text\n",
    "\n",
    "\n",
    "def main(query, K=10):\n",
    "    df = get_google_results(query)\n",
    "    df = extract_paper_ids(df)\n",
    "    df = add_paper_info(df)\n",
    "    df = parse_paper_info(df)\n",
    "    get_pdfs(df, \"pdfs/\")\n",
    "    df = add_pdf_paths(df, \"pdfs/\")\n",
    "    df = read_pdfs(df)\n",
    "    df = preprocess_text(df)\n",
    "    all_text = get_all_text(df)\n",
    "    df_text = create_text_df(all_text)\n",
    "    df_text = add_embeddings(df_text)\n",
    "    query_embedding = get_embeddings(query)\n",
    "    df_text = get_cosine_similarities(df_text, query_embedding)\n",
    "    df_text = sort_by_cosine_similarity(df_text)\n",
    "    df_text = get_top_results(df_text, K)\n",
    "    df_text = add_tldrs(df_text)\n",
    "    return df_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37809333b4224a009144c8a0229db703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pdfs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a504f4229d40daa7e8ff17d1229342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd97f864a91d4fee9c60f83ac270c1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca7b7d48c644aa9d2c42c63e89ef19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_text = main(query, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_question_chatgpt(\n",
    "    df,\n",
    "    question=\"What is the impact of creatine on cognition?\",\n",
    "    k=5,\n",
    "    instructions=\"Instructions: Using the provided web search results, write a comprehensive reply to the given query. If you find a result relevant definitely make sure to cite the result using [[number](URL)] notation after the reference. End your answer with a summary. A\\nQuery:\",\n",
    "    max_len=3000,\n",
    "    debug=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context_chatgpt(question, df, k=k)\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        # prompt = f'''{context} \\n\\n Instructions: Using the provided literature with sources, write a comprehensive reply to the given query. Make sure to cite results using [[number](URL)] notation after the reference. If the provided search results refer to multiple subjects with the same name, write separate answers for each subject. You can skip a citation which you dont find relevant to the query. \\nQuery:{question}\\nAnswer:'''\n",
    "        prompt = f\"\"\"{context} \\n\\n{instructions} {question}\\nAnswer:\"\"\"\n",
    "        return prompt\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def create_context_chatgpt(question, df, k=5):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    returns = []\n",
    "    count = 1\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df[:k].iterrows():\n",
    "\n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(\n",
    "            \"[\"\n",
    "            + str(count)\n",
    "            + \"] \"\n",
    "            + row[\"tldr\"]\n",
    "            + \"\\nURL: \"\n",
    "            + \"https://www.semanticscholar.org/paper/\"\n",
    "            + row[\"paperId\"]\n",
    "        )\n",
    "        count += 1\n",
    "    # Return the context\n",
    "    return \"\\n\\n\".join(returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>tldr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>79bf58971512598569f3a0113b520a33e5176696</td>\n",
       "      <td>Towards the Exploitation of Statistical Langua...</td>\n",
       "      <td>[[-0.2042403221130371, 2.177624464035034, 0.12...</td>\n",
       "      <td>0.865970</td>\n",
       "      <td>In this work, we describe our first attempt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>fba934b8955022742636b211bf07fc1aada74ed4</td>\n",
       "      <td>Towards the Exploitation of Statistical Langua...</td>\n",
       "      <td>[[-0.2042403221130371, 2.177624464035034, 0.12...</td>\n",
       "      <td>0.865970</td>\n",
       "      <td>In this work, we describe our first attempt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde</td>\n",
       "      <td>##t - 3. it has learned to code ( and blog and...</td>\n",
       "      <td>[[-0.5793511867523193, 1.6754060983657837, -0....</td>\n",
       "      <td>0.847437</td>\n",
       "      <td>A new study has found that the use of artifici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>, n., schubotz, m., gipp, b. : analyzing seman...</td>\n",
       "      <td>[[-0.27326077222824097, 1.6272714138031006, 0....</td>\n",
       "      <td>0.846910</td>\n",
       "      <td>A hybrid approach to academic plagiarism detec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>6 ), 112 : 1 { 112 : 42 ( 2019 ). https : / / ...</td>\n",
       "      <td>[[-0.39709630608558655, 2.05199933052063, 0.53...</td>\n",
       "      <td>0.845356</td>\n",
       "      <td>A cross-language plagiarism detection system b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paperId  \\\n",
       "59  79bf58971512598569f3a0113b520a33e5176696   \n",
       "58  fba934b8955022742636b211bf07fc1aada74ed4   \n",
       "33  0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde   \n",
       "15  64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "13  64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "\n",
       "                                                 text  \\\n",
       "59  Towards the Exploitation of Statistical Langua...   \n",
       "58  Towards the Exploitation of Statistical Langua...   \n",
       "33  ##t - 3. it has learned to code ( and blog and...   \n",
       "15  , n., schubotz, m., gipp, b. : analyzing seman...   \n",
       "13  6 ), 112 : 1 { 112 : 42 ( 2019 ). https : / / ...   \n",
       "\n",
       "                                            embedding  cosine_similarity  \\\n",
       "59  [[-0.2042403221130371, 2.177624464035034, 0.12...           0.865970   \n",
       "58  [[-0.2042403221130371, 2.177624464035034, 0.12...           0.865970   \n",
       "33  [[-0.5793511867523193, 1.6754060983657837, -0....           0.847437   \n",
       "15  [[-0.27326077222824097, 1.6272714138031006, 0....           0.846910   \n",
       "13  [[-0.39709630608558655, 2.05199933052063, 0.53...           0.845356   \n",
       "\n",
       "                                                 tldr  \n",
       "59  In this work, we describe our first attempt to...  \n",
       "58  In this work, we describe our first attempt to...  \n",
       "33  A new study has found that the use of artifici...  \n",
       "15  A hybrid approach to academic plagiarism detec...  \n",
       "13  A cross-language plagiarism detection system b...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>tldr</th>\n",
       "      <th>unique_index</th>\n",
       "      <th>id</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>79bf58971512598569f3a0113b520a33e5176696</td>\n",
       "      <td>Towards the Exploitation of Statistical Langua...</td>\n",
       "      <td>[[-0.2042403221130371, 2.177624464035034, 0.12...</td>\n",
       "      <td>0.865970</td>\n",
       "      <td>In this work, we describe our first attempt to...</td>\n",
       "      <td>79bf58971512598569f3a0113b520a33e5176696914</td>\n",
       "      <td>79bf58971512598569f3a0113b520a33e5176696</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>fba934b8955022742636b211bf07fc1aada74ed4</td>\n",
       "      <td>Towards the Exploitation of Statistical Langua...</td>\n",
       "      <td>[[-0.2042403221130371, 2.177624464035034, 0.12...</td>\n",
       "      <td>0.865970</td>\n",
       "      <td>In this work, we describe our first attempt to...</td>\n",
       "      <td>fba934b8955022742636b211bf07fc1aada74ed4682</td>\n",
       "      <td>fba934b8955022742636b211bf07fc1aada74ed4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde</td>\n",
       "      <td>##t - 3. it has learned to code ( and blog and...</td>\n",
       "      <td>[[-0.5793511867523193, 1.6754060983657837, -0....</td>\n",
       "      <td>0.847437</td>\n",
       "      <td>A new study has found that the use of artifici...</td>\n",
       "      <td>0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde255</td>\n",
       "      <td>0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>, n., schubotz, m., gipp, b. : analyzing seman...</td>\n",
       "      <td>[[-0.27326077222824097, 1.6272714138031006, 0....</td>\n",
       "      <td>0.846910</td>\n",
       "      <td>A hybrid approach to academic plagiarism detec...</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f148</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>6 ), 112 : 1 { 112 : 42 ( 2019 ). https : / / ...</td>\n",
       "      <td>[[-0.39709630608558655, 2.05199933052063, 0.53...</td>\n",
       "      <td>0.845356</td>\n",
       "      <td>A cross-language plagiarism detection system b...</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f686</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>provides over - current pds, we compared it to...</td>\n",
       "      <td>[[-0.2686731815338135, 1.6583670377731323, 0.4...</td>\n",
       "      <td>0.844149</td>\n",
       "      <td>Researchers have developed a machine-to-machin...</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f518</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>( 1991 ). https : / / doi. org / 10. 1007 / bf...</td>\n",
       "      <td>[[-0.09546034783124924, 1.5630769729614258, -0...</td>\n",
       "      <td>0.843557</td>\n",
       "      <td>A new algorithm for automatic plagiarism detec...</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f409</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>[CLS] detecting machine - obfuscated plagiaris...</td>\n",
       "      <td>[[0.23195765912532806, 1.7406513690948486, 0.4...</td>\n",
       "      <td>0.835629</td>\n",
       "      <td>Researchers at the University of Wuppertal and...</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f538</td>\n",
       "      <td>64e994b6bd61ab6be34543f42bd043b8ebdde22f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>930f526de3b0fc3b7d9fab1bd56f36272ca86b17</td>\n",
       "      <td>##® ( n. d. ). the free online automated parap...</td>\n",
       "      <td>[[-0.17010152339935303, 1.6247491836547852, 0....</td>\n",
       "      <td>0.832636</td>\n",
       "      <td>Free online paraphrasing tools rely principall...</td>\n",
       "      <td>930f526de3b0fc3b7d9fab1bd56f36272ca86b17671</td>\n",
       "      <td>930f526de3b0fc3b7d9fab1bd56f36272ca86b17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b</td>\n",
       "      <td>Using Word Embedding for Cross-Language Plagia...</td>\n",
       "      <td>[[0.3351580500602722, 1.5683748722076416, 0.88...</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>This paper proposes to use distributed represe...</td>\n",
       "      <td>1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b55</td>\n",
       "      <td>1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     paperId  \\\n",
       "59  79bf58971512598569f3a0113b520a33e5176696   \n",
       "58  fba934b8955022742636b211bf07fc1aada74ed4   \n",
       "33  0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde   \n",
       "15  64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "13  64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "9   64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "11  64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "0   64e994b6bd61ab6be34543f42bd043b8ebdde22f   \n",
       "42  930f526de3b0fc3b7d9fab1bd56f36272ca86b17   \n",
       "62  1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b   \n",
       "\n",
       "                                                 text  \\\n",
       "59  Towards the Exploitation of Statistical Langua...   \n",
       "58  Towards the Exploitation of Statistical Langua...   \n",
       "33  ##t - 3. it has learned to code ( and blog and...   \n",
       "15  , n., schubotz, m., gipp, b. : analyzing seman...   \n",
       "13  6 ), 112 : 1 { 112 : 42 ( 2019 ). https : / / ...   \n",
       "9   provides over - current pds, we compared it to...   \n",
       "11  ( 1991 ). https : / / doi. org / 10. 1007 / bf...   \n",
       "0   [CLS] detecting machine - obfuscated plagiaris...   \n",
       "42  ##® ( n. d. ). the free online automated parap...   \n",
       "62  Using Word Embedding for Cross-Language Plagia...   \n",
       "\n",
       "                                            embedding  cosine_similarity  \\\n",
       "59  [[-0.2042403221130371, 2.177624464035034, 0.12...           0.865970   \n",
       "58  [[-0.2042403221130371, 2.177624464035034, 0.12...           0.865970   \n",
       "33  [[-0.5793511867523193, 1.6754060983657837, -0....           0.847437   \n",
       "15  [[-0.27326077222824097, 1.6272714138031006, 0....           0.846910   \n",
       "13  [[-0.39709630608558655, 2.05199933052063, 0.53...           0.845356   \n",
       "9   [[-0.2686731815338135, 1.6583670377731323, 0.4...           0.844149   \n",
       "11  [[-0.09546034783124924, 1.5630769729614258, -0...           0.843557   \n",
       "0   [[0.23195765912532806, 1.7406513690948486, 0.4...           0.835629   \n",
       "42  [[-0.17010152339935303, 1.6247491836547852, 0....           0.832636   \n",
       "62  [[0.3351580500602722, 1.5683748722076416, 0.88...           0.831746   \n",
       "\n",
       "                                                 tldr  \\\n",
       "59  In this work, we describe our first attempt to...   \n",
       "58  In this work, we describe our first attempt to...   \n",
       "33  A new study has found that the use of artifici...   \n",
       "15  A hybrid approach to academic plagiarism detec...   \n",
       "13  A cross-language plagiarism detection system b...   \n",
       "9   Researchers have developed a machine-to-machin...   \n",
       "11  A new algorithm for automatic plagiarism detec...   \n",
       "0   Researchers at the University of Wuppertal and...   \n",
       "42  Free online paraphrasing tools rely principall...   \n",
       "62  This paper proposes to use distributed represe...   \n",
       "\n",
       "                                   unique_index  \\\n",
       "59  79bf58971512598569f3a0113b520a33e5176696914   \n",
       "58  fba934b8955022742636b211bf07fc1aada74ed4682   \n",
       "33  0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde255   \n",
       "15  64e994b6bd61ab6be34543f42bd043b8ebdde22f148   \n",
       "13  64e994b6bd61ab6be34543f42bd043b8ebdde22f686   \n",
       "9   64e994b6bd61ab6be34543f42bd043b8ebdde22f518   \n",
       "11  64e994b6bd61ab6be34543f42bd043b8ebdde22f409   \n",
       "0   64e994b6bd61ab6be34543f42bd043b8ebdde22f538   \n",
       "42  930f526de3b0fc3b7d9fab1bd56f36272ca86b17671   \n",
       "62   1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b55   \n",
       "\n",
       "                                          id  unique_id  \n",
       "59  79bf58971512598569f3a0113b520a33e5176696          3  \n",
       "58  fba934b8955022742636b211bf07fc1aada74ed4          5  \n",
       "33  0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde          0  \n",
       "15  64e994b6bd61ab6be34543f42bd043b8ebdde22f          2  \n",
       "13  64e994b6bd61ab6be34543f42bd043b8ebdde22f          2  \n",
       "9   64e994b6bd61ab6be34543f42bd043b8ebdde22f          2  \n",
       "11  64e994b6bd61ab6be34543f42bd043b8ebdde22f          2  \n",
       "0   64e994b6bd61ab6be34543f42bd043b8ebdde22f          2  \n",
       "42  930f526de3b0fc3b7d9fab1bd56f36272ca86b17          4  \n",
       "62  1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b          1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  column paperId has duplicate values, I want to assign a unique integer to each row based on the column paperId \n",
    "\n",
    "def unique_id(df):\n",
    "    df['unique_id'] = df['paperId'].astype('category').cat.codes\n",
    "    return df\n",
    "\n",
    "unique_id(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[1] In this work, we describe our first attempt to detect plagiarised segments in a text employing statistical Language Models (LMs) and perplexity. The preliminary experiments carried out on two specialised and literary corpora (including original, part-of-speech and stemmed versions) show that perplexity of a text segment, given a Language Model calculated over an author text, could be a relevant feature in plagiarism detection.\n",
       "URL: https://www.semanticscholar.org/paper/79bf58971512598569f3a0113b520a33e5176696\n",
       "\n",
       "[2] In this work, we describe our first attempt to detect plagiarised segments in a text employing statistical Language Models (LMs) and perplexity. The preliminary experiments carried out on two specialised and literary corpora (including original, part-of-speech and stemmed versions) show that perplexity of a text segment, given a Language Model calculated over an author text, could be a relevant feature in plagiarism detection.\n",
       "URL: https://www.semanticscholar.org/paper/fba934b8955022742636b211bf07fc1aada74ed4\n",
       "\n",
       "[3] A new study has found that the use of artificial intelligence (AI) in data-driven artificial intelligence systems has led to bias in data-driven AI systems. The study found that the use of AI in data-driven artificial intelligence systems has led to bias in data-driven AI systems. It also found that the use of AI in data-driven artificial intelligence systems has led to bias in data-driven AI systems.\n",
       "URL: https://www.semanticscholar.org/paper/0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde\n",
       "\n",
       "[4] A hybrid approach to academic plagiarism detection was presented at the 17th acm / ieee joint conference on digi- tal libraries ( jcdl ). In this paper, a hybrid approach to academic plagiarism detection was presented. The hybrid approach uses semantic concept patterns to detect academic plagiarism. It is based on the concept of semantic similarity detection based graph approach.\n",
       "URL: https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f\n",
       "\n",
       "[5] A cross-language plagiarism detection system based on a knowledge graph and based on explicit semantic analysis has been developed. The system can detect cross-language plagiarism over continuous space and knowledge graph based representations of language. It can also detect cross-language plagiarism over continuous space and knowledge graph based representations of language.\n",
       "URL: https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f\n",
       "\n",
       "[6] Researchers have developed a machine-to-machine (M2M) plagiarism detection system that can distinguish between original and machine-to-machine (M2M) paraphrased text. The system is based on a word2vec embedding model and anm classier. Researchers tested the system on ten machine-to-machine (M2M) paraphrased articles selected at random from a document test set. turnitin found the correct source in all cases.\n",
       "URL: https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f\n",
       "\n",
       "[7] A new algorithm for automatic plagiarism detection has been developed. The algorithm is based on a state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-art state-of-the-\n",
       "URL: https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f\n",
       "\n",
       "[8] Researchers at the University of Wuppertal and the University of Konstanz have developed a machine-to-machine (M2M) plagiarism detection system. The system uses word embedding models to detect machine-to-machine (M2M) plagiarism. The system is capable of detecting machine-to-machine (M2M) plagiarism tom a s folt ynek1 and tom a s folt ynek3 and tom a s folt ynek4 and tom a s folt ynek5 and tom a s folt ynek6.\n",
       "URL: https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f\n",
       "\n",
       "[9] Free online paraphrasing tools rely principally on synonym substitu - tion without the overall syntax of the sentence, resulting in language which is unidiomatic at best, incomprehensible at worst. When a sentence was taken from the assessment scenario, one day, while doug was out walking, he felt lightheaded and then lost consciousness and fell to the ground.\n",
       "URL: https://www.semanticscholar.org/paper/930f526de3b0fc3b7d9fab1bd56f36272ca86b17\n",
       "\n",
       "[10] This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following: (a) we introduce new cross-language similarity detection methods based on distributed representation of words; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15% for English-French similarity detection at chunk level (88.5% at sentence level).\n",
       "URL: https://www.semanticscholar.org/paper/1936f64ef3d2a4e2e1dc89b40f3f40aecdeaf69b \n",
       "\n",
       "Instructions: Using the provided web search results, write a comprehensive reply to the given query. If you find a result relevant definitely make sure to cite the result using [[number](URL)] notation after the reference. End your answer with a summary. A\n",
       "Query: do language models plagiarize?\n",
       "Answer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = answer_question_chatgpt(\n",
    "    df_text,\n",
    "    question=query,\n",
    "    k=K,\n",
    "    instructions=\"Instructions: Using the provided web search results, write a comprehensive reply to the given query. If you find a result relevant definitely make sure to cite the result using [[number](URL)] notation after the reference. End your answer with a summary. A\\nQuery:\",\n",
    ")\n",
    "printmd(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Language models, especially statistical ones, may be applied to detect plagiarized segments in a text by employing perplexity, as demonstrated in a study that used two specialized and literary corpora [[1](https://www.semanticscholar.org/paper/79bf58971512598569f3a0113b520a33e5176696)][[2](https://www.semanticscholar.org/paper/fba934b8955022742636b211bf07fc1aada74ed4)]. Another paper describes a hybrid approach to academic plagiarism detection using semantic concept patterns and detecting plagiarism based on semantic similarity detection through graph approach [[4](https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f)]. Furthermore, researchers have developed a machine-to-machine (M2M) plagiarism detection system that applies a word2vec embedding model for distinguishing between original and machine-to-machine (M2M) paraphrased text [[6](https://www.semanticscholar.org/paper/64e994b6bd61ab6be34543f42bd043b8ebdde22f)]. On the other hand, free online paraphrasing tools often rely on synonym substitution without considering sentence syntax and may result in unidiomatic or incomprehensible language at times [[9](https://www.semanticscholar.org/paper/930f526de3b0fc3b7d9fab1bd56f36272ca86b17)].\n",
       "\n",
       "In summary, while language models and related techniques may be utilized for plagiarism detection, there are instances where they might be less effective, such as with paraphrasing tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = generate_answer(prompt)\n",
    "printmd(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
