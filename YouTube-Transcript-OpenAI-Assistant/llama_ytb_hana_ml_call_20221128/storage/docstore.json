{"docstore/metadata": {"6555f559-656f-4f88-8982-8219e333a9f4": {"doc_hash": "dedfc950189f3f32e31b761982631d12ea19f6383b3a21c2d6b8178c4bba531f"}, "1fa14299-49e1-4ab4-900c-89677384657e": {"doc_hash": "dd42d773cf6554e9b054c472b1478fcd3d71c6160911aa2ace506162f876ed78", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "745c7409-b389-41e2-ae58-7fae1f5ade74": {"doc_hash": "ca969cead1333d0db7f0298bc5f0d5056649ace19d2e87822e290e1be4cf16bd", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "083d227d-1551-482c-b803-8065cb6500c0": {"doc_hash": "0a90bc5a4d7de5583d4eebf0ccb989be0410c7115024f530ca4106e57a2124f8", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "367d2294-9bac-4a86-82e5-5548e5f89a8d": {"doc_hash": "f91c75a1bb32ba56af20e13d7e3b2126cd598f21dc7879e16f0032f6b4b73799", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "339ffd2d-49e9-47f2-92d4-6976df9bc82a": {"doc_hash": "bd8ac4fc563266db0a6beb7af24cc99dea11aac48bbe896e4b4073213da70d37", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "931fb36c-94b6-461d-a932-febc9bf6b40f": {"doc_hash": "71bf7056e234b692c38e72d9013a660a0aae139c583dcc285318127d4234146d", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "d5187b22-e396-441d-af05-5cd79a07f701": {"doc_hash": "9c559a73638c200ac620b5ca9cee17ed1fffa20c49639f0d311b8b9c5ff61176", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "cc2300fa-d504-420c-8b1d-ad65b05ac1f1": {"doc_hash": "51fb6c3cf64bba5d84b6043630264f0714fc4aa75bd22835acd6e1f50141a715", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}, "e002246b-8e7e-40c6-9de9-7faebdc4c4ab": {"doc_hash": "08114a63e8aff8cb079e998c55ce1b425c607bbcb8a6b1f7f527d9801f150418", "ref_doc_id": "6555f559-656f-4f88-8982-8219e333a9f4"}}, "docstore/data": {"1fa14299-49e1-4ab4-900c-89677384657e": {"__data__": {"text": "and we're live\nperfect so please take it away hi\neveryone and a warm welcome to today's\nsap Community call my name is Susan and\nI am proud of the sap Hana product\nmanagement team and I will be your host\ntoday and I'm really really excited\nabout the topic of today's call so we\nwill first get an introduction to\nmachine learning in sap Hana cloud and\nafterwards we'll finally kick off our\nsap Hana 12 machine learning challenge\nso thanks already for joining here and\nyour big interest in the challenge so\nlet me introduce the most important\npeople today we're having in the back\nend with me Savage whose competency for\ndata science and machine learning at sap\nAndreas Foster our machine learning\nexpert in Sap's Global Center of\nExcellence Yannick sharp our customer\nadvisor for machine learning and my\nfellow product manager Christoph Morgan\nsenior director of product management\nsap Hana predictive and machine learning\nso our call will be 60 Minutes long and\nthe recording will be available under\nthe exact link you're joining us today\nso one last thing before I hand it over\nto our speakers make sure to use our q a\ntools so I'm right next to the video in\nYouTube you see the chat window just\npost all your questions in there and\nwe're hopefully having enough time at\nthe end of our call to answer all your\nquestions either in a written format in\nthe chat or live in a spoken format so\nwith this Christoph I don't want to\nsteal any more time from you I'm handing\nit over\nthank you very much Susan\nfor the nice introduction and also warm\nwelcome from my side to our Hana machine\nLearning Community chilling uh challenge\nI'm really excited we have been able to\nput this together with our machine\nlearning experts from the field\num we'll also have uh put to put\ntogether the the challenge itself\nand yeah basically as you already kind\nof outlined what we want to do in the\nnext couple of minutes quickly I will\nintroduce the the Hana ml capabilities\nand overview the topic very briefly\nthen Yannick will give you a demo\noverview on how to make use of the Hana\nmachine learning capabilities\nand\num yeah and again Sarah will then\ndescribe the challenge itself the the\ntopic which is the key use case for for\nour Challenge and also Andreas will then\nkind of outline how we organize the\noverall uh Challenge from our process\nperspective when we meet how we meet uh\nhow we can interact and yeah how you can\nget access to the the Hana Cloud\nchallenge\nalso here's uh uh some some pictures of\nall of us across the regional experts\nwhich you which will be joining our open\noffice called uh regularly uh in the\ndifferent regions will also come to them\nand introduce them as well so\nHana machine learning is one of the key\ncapabilities of the Hana cloud or the\nHana database in in general along with\nother Advanced processing capabilities\nlike spatial graph or storing data in\nthe Json documents or some of the\nextended key capabilities which make\nHana let's say a unique and Rich\nmulti-model database and you can build\nyour applications on btp on sap Hana\nCloud for example and directly Infuse\nthem with those those Advanced\ncapabilities without the needs need to\nadd another spatial application server\nor machine learning\nlet's say infrastructure it's all part\nof Hana cloud in the first place and\nthat's why it makes this so attractive\nto yeah apply machine learning scenarios\ndirectly with sap Hana\nuh we will also showcase our native\nclient interfaces for data scientists in\nIron python so in case you don't know\nthem uh yet we will showcase them to you\nwe have two key AI function libraries\nembedded in Hana Cloud the first one is\nthe automated predictive Library which\ntargets yeah the classic machine\nlearning scenarios like classification\nregression and Times News forecasting\nsome others and the key value of the\nautomated predictive library is that\nthere's a simple set of functions which\neverybody can use non-data scientists\ndevelopers\nadministrators of a Hana system can\nreally use because the engine automates\nthe complete step from accessing my data\nselecting the best variables", "doc_id": "1fa14299-49e1-4ab4-900c-89677384657e", "embedding": null, "doc_hash": "dd42d773cf6554e9b054c472b1478fcd3d71c6160911aa2ace506162f876ed78", "extra_info": null, "node_info": {"start": 0, "end": 4083, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "3": "745c7409-b389-41e2-ae58-7fae1f5ade74"}}, "__type__": "1"}, "745c7409-b389-41e2-ae58-7fae1f5ade74": {"__data__": {"text": "engine automates\nthe complete step from accessing my data\nselecting the best variables data\npreparation maybe encoding even of uh\ndistinct columns missing value handling\nall that and comes up with the best\npossible model that's why it's very very\npopular uh yeah AI function library\nbecause it provides you with a high\nproductivity and fast time to Value to\nkind of come up with a really really\ngood machine learning model in the first\nplace\nour second Library more for the expert\nis the predictive analysis Library it\nprovides education for the same or\nsimilar scenarios like the automated\npredictive library but those are kind of\ndistinct algorithms the experts can\nchoose from like for example gradient\nboosting classification or profit time\nseries forecasting so it provides\ntrending algorithm along with standard\nand classic algorithm in those\ndistinctive domains\nplus adding uh your expert support\ncapabilities like uh segmented\nforecasting invocation explainability\nfor model interpretability\nor uh yeah hyperscaler not hyperscaler\nhyper parameter model selection and\ncapabilities like that it's also driven\nby the SQL interface as well as the r\nand python machine learning clients and\nhere\nyou see that there's a rich set of\nfunctions and algorithms available with\nthe predictive analysis Library it uh it\nis distinguished a little bit between\nthe on-premise sap Hana and the sap Hana\nCloud here in our challenge we are\nsharing a Hana Cloud instance which has\nall the algorithms you see on the slide\navailable\nwhich you can choose and make use of as\npart of the the challenge everything\nbluish and black is also available uh\nwithin johana on premise installation\num so a rich set and maybe Swiss army\nknife to with all kinds of algorithms\nand the best is as a data scientist and\nas you may already know those algorithms\nyou can leverage them via the pisman are\nmachine learning clients where you\nbasically script in those languages\nbut you run in Hana as the interface\ngenerates secret on the Fly and execute\nwith sabiana data is exposed by a data\nframe concept similar to what you may\nalready know in Python R and then the\nmethods are wrapped in python or R and\nyou can then script\num with your python Jupiter notebook\nlike you would be scripting with\nscikit-learn for example everything is\nreally similar and close so the\nexperience and productivity for you or a\ndata scientist is really good\nso these are our machine learning\nclients and I guess this was the the\nbrief info from my side and I think\nwhat's most interesting how uh\ndoes it look like live and I think\nYannick is now giving you the demo\nexperience\nperfect thank you Chris\nso let me share my screen and\nbefore we jump into the tool and my\npython environment I want to first show\nyou a small architecture of the demo and\nwhat we will see in the next couple of\nminutes so I I will be working from my\nlocal Jupiter lab environment but you\ncan of course also use other pricing\nenvironments to leverage our Hana\nmachine learning capabilities\nand what I will do first is install the\nHana ml package which will contain the\nhair functionalities Crystal introduced\nand I will then be able to use them\nfrom my local python environment without\nmoving the data into my my local\nenvironment so I can\nstay here in my python environment but\nstill use the functionalities in Hana\nand the data can stay where it is so\nreally we brought the algorithms to the\ndata\nand with these functionalities I will\nthen show you how I can predict a\nquality of a production\nand in my demo and yeah I cannot see you\nscreaming Susan also cannot gets new\nscreen mature that's a general issue\nmaybe you can re-share again oh sorry\nabout that no problem\nyeah it's\nski\nI mean this is life it says maybe\nsomebody can take\ncan take over the sharing and then I'll\nrestart again because it's a whole Zoom\nis kept Frozen sorry about that\nno no problem maybe I can find Andreas\ndo you wanna\ngo ahead with kind of your part\nare you ready then we come back to the\ndemo once uh the unexpect\nI was hoping to talk over this night\nthat yeah so\nyeah but", "doc_id": "745c7409-b389-41e2-ae58-7fae1f5ade74", "embedding": null, "doc_hash": "ca969cead1333d0db7f0298bc5f0d5056649ace19d2e87822e290e1be4cf16bd", "extra_info": null, "node_info": {"start": 4008, "end": 8083, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "1fa14299-49e1-4ab4-900c-89677384657e", "3": "083d227d-1551-482c-b803-8065cb6500c0"}}, "__type__": "1"}, "083d227d-1551-482c-b803-8065cb6500c0": {"__data__": {"text": "unexpect\nI was hoping to talk over this night\nthat yeah so\nyeah but now we can do it it's working\nyeah can you see my screen now yes we\ncan okay okay sorry about that some some\ntechnical problems\num yeah so I hope you can see now my my\narchitecture so to maybe summarize that\nI'll stay in my local Jupiter\nenvironment my low comparison\nenvironment you can of course use also\nuse other python environment\num to install the Hana ml package from\nthere you can leverage them these\nfunctionalities in Hana cloud\nand I would say let's let's take a look\nat the concrete example and we will of\ncourse also find the code I'm about to\nshare in a blog post we published in in\na GitHub repository so if you want to\nfollow\num demo later in through the blog post\nthat is of course also possible\nokay\nso I hope you can see now my local\nJupiter environment\nand\nI said the first thing you have to\ninstall is the Hana package which\nleverages the functionality is Crystal\nintroduced\nthrough so through this package I am now\nable to use the predictive analyzers\nlibrary and auto made a predictive\nlibrary and connect to my Hana cloud\nsystem\nso I installed it and uh then imported\nand now of course the next step is to\nactually connect to my\num Hana system and you have different\noptions to do this so\nfor the challenge\num you might have already tested the\nconnection from your python environment\nbut one of the scripts in the git\nRepository\nyou're able to copy the credentials into\nthe fields and then of course yeah test\nthe connection\nbut of course you can also hide your\ncredentials and don't have them visible\nin in your cell as script and I've for\nthis I've added a security key which is\nalso described in the blog post which\ncould contains my credentials and now\nI'm able to connect to my Hana cloud\nsystem through this security key\nand this connection variable here will\nthen be very important for me to yeah\ncreate the Hana data frames and to of\ncourse then save my results in my Hana\nCloud later on\nand\nnow there are two options so the first\nscenario could be that the data is\ncurrently locally here on my laptop and\nI want to upload it into my Hana cloud\nsystem\nso for this demo I've prepared some some\ndata which is of course not the\nchallenge we didn't want to make it that\nthat simple\nand I've yeah then trans transformed\nthis later this data a little bit added\nin ide and then I will pushing it now\ndirectly into my Hana cloud system into\nmy schema\nand you would be able to do this as well\nyou can take the data from The Challenge\nload it locally and then push it into\nthe Hana cloud system\nfor example is providing to you\nthen later on the data is of course\nalready yeah lying in your Hana cloud\nsystem and you don't always want to push\nit into Hana every single time when you\ncreate the Hana data frame and of course\nin reality\noften the data is already in your\nbackend system in this hopefully not\num only locally on your laptop\nand I can create this Hana data frame\nalso in a couple of different ways\nwithout moving the data into my local\nenvironment and one option you see here\nin the script\nso remember I created this connection\nvariable\nand I now have the option to execute an\nSQL statement very simple here which\njust points to the data in my schema in\nmy Hana cloud\nand with with this I've now created a\nHana data frame\nwith which I can now work I can do data\nunderstanding I can do data preparation\nand I can also Leverage The Machine\nlearning capabilities without moving\nthis data into my local environment so\nit it's kind of like an arrow\npointing to the data in My Hangout file\nsystem\nokay so this is prepared so let's take a\nlook at some data preparation or data\nunderstanding steps so for example if\nyou first have to clean your data before\nyou actually can do machine learning and\nfor this you have of course a couple of\nfunctions already available here to you\nthrough the Hana ml package for example\nthe variable\nquality which I actually want to predict\nis in the wrong format and I can get\nquickly change it into a character\nformat so that the", "doc_id": "083d227d-1551-482c-b803-8065cb6500c0", "embedding": null, "doc_hash": "0a90bc5a4d7de5583d4eebf0ccb989be0410c7115024f530ca4106e57a2124f8", "extra_info": null, "node_info": {"start": 8103, "end": 12158, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "745c7409-b389-41e2-ae58-7fae1f5ade74", "3": "367d2294-9bac-4a86-82e5-5548e5f89a8d"}}, "__type__": "1"}, "367d2294-9bac-4a86-82e5-5548e5f89a8d": {"__data__": {"text": "the wrong format and I can get\nquickly change it into a character\nformat so that the algorithms automatic\nautomatically detect that it's probably\na classification what it's supposed to\ndo\nand of course I can do complex for data\npreparation steps here as well I could\nexecute of course also SQL scripts to to\nclean the data\num I can also visualize the data so here\nI'm doing a small description of the\ndata and then I'm only collecting the\nactual report\nof this describe method so the heavy\nlifting stays in Hana and I'm only\ncollecting small samples of the data\nlike this described report into my local\nenvironment to visualize it\nokay now of course in reality data\nunderstanding and data preparation takes\nquite a lot of time\nbut I would like to move on now to\num yeah the machine learning part\nbecause I think it's very powerful and I\ncan yeah work just like I'm used to with\nalso open source package like cycle\nlearn or other packages to now split the\ndata into a training and the testing set\nbefore I train my machine learning\nalgorithm and this is done through\nthis cell so through this command I'm\nnow I'm splitting the data into 80\ntraining set and 20 of the data I will\npreserve for yeah testing my train\nmachine learning modeling\nI can then control the size of my\ntraining and testing set\nand then I can proceed to\num do machine learning and as Christoph\nmentioned there are a lot of options\navailable now for you to solve the\nchallenge and I will choose one\npossibility which is an algorithm in the\npredictive analysis Library\nand I'm a big fan of the random Forest\num which is yeah a great method to you\nknow predict if a transaction if a\ncreative product will be of good quality\nor bad quality and\nfor this I'm now using the random Forest\nclassifier here and the predictive\nanalyzers library and I first want to\ntrain this\num model with a lot of threes so\num to see kind of how does the error in\nmy algorithm\num convert converge and I can optimize\nthis algorithm here just like I'm used\nto in the open source world so I can now\ngo into more\num hyper parameter tuning and it's it's\nreally just like if I would be um\noptimizing an algorithm from Cycles\nlearn\nwhen I've trained the the model I can\nthen create prediction with it\num predict\num if the product will be of good or bad\nquality I can look at the score and the\nconfidence how how sure is the algorithm\nif a product will be of good or bad\nquality\nI can further evaluate it so I can for\nexample of course look at the confusion\nMatrix how good is the algorithm in its\ndecision making this one here is in\nSample but I can of course also apply it\nto the testing data which I've kind of\npreserved on the side and look at the\nconfusion Matrix out of sample\nto to control if my machine learning\nmodel is actually of good quality\nand yeah of course then many many more\ncapabilities to actually evaluate\num the model of course\num random Forest is also a really\namazing algorithm because I don't only\nhave the prediction but I also have\num kind of more insights\num\nwhat which variables were of importance\nwhich\num variables were not as important to\npredict if a product will be of good or\nbad quality\nso I also generate not only the\npredictions but really further insights\nfor the business\nand yeah I kind of want to scroll\nthrough here so I'm now doing a lot of\nhyper parameter tuning here and\nin the end I of course have one final\nmodel which I'm yeah which I'm happy\nwith\num which I then want to of course also\nsave in my Hana cloud and maybe use it\nat a later time again and for this I'm\nnow also able to create a model storage\ndirectly in in my Hana\nand in there I can then save my final\nmachine learning model which I've\noptimized\nand then later on of course always load\nit and use it for for predictions and\nfor example in here you see I've already\ncreated\num two random Forest models which I can\nthen further use\nnow this was just one example how to\nLeverage The Machine learning\ncapabilities in our cloud and there are\nof course many more and for you of\ncourse it is important then when you\nstart with it how do you", "doc_id": "367d2294-9bac-4a86-82e5-5548e5f89a8d", "embedding": null, "doc_hash": "f91c75a1bb32ba56af20e13d7e3b2126cd598f21dc7879e16f0032f6b4b73799", "extra_info": null, "node_info": {"start": 12146, "end": 16228, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "083d227d-1551-482c-b803-8065cb6500c0", "3": "339ffd2d-49e9-47f2-92d4-6976df9bc82a"}}, "__type__": "1"}, "339ffd2d-49e9-47f2-92d4-6976df9bc82a": {"__data__": {"text": "more and for you of\ncourse it is important then when you\nstart with it how do you find the\ndocumentation how to actually\num yeah tune such an algorithm\nand for this I want to quickly show you\nthe\n[Music]\nlink to the\ndocumentation there it is\nso under the link you will then find of\ncourse a lot of more examples and you\ncan you can try and in here you will\nalso have the documentation how you\nactually yeah tune these algorithms and\num you find a lot more possibilities\num there as well\nand with that I would say we are now\nready to look at the actual challenge\nwhich you will have to solve in this ml\nCommunity challenge\nso Sarah\ncan you tell us a little bit more about\nthe actual challenge\nsure we prepared a lot of fun things for\nyou\nand maybe let's start with the concept\nthat we prepared for you for our\ncommunity challenge so the idea is that\nwe have some hard experimental learning\nespecially for you\nso Yannick when we move to the next\nslide\nyeah seems to have problems again\nno worries\njust give it a few seconds\nso maybe you can take over the share the\nscreen sharing\nthank you\nthere we go yes we prepared a Hana cloud\nsystem for you so you should all have\naccess to that\num if you don't it's also described in\nthe blog post in the kickoff blog post\nhow you can get access to it\nthen we have a nice challenge for you I\nwill give you a few more insights about\nthat one later on and as Yannick already\nmentioned we have some expert content\nyeah you have a lot of GitHub links you\nalso have some Hands-On tutorials that\nmight help you doing the challenge and\nin case you get stuck we are of course\nalways there for you so we have some\nopen Office hours twice a week so this\nis again also a zoom call which is not\nrecorded not live on YouTube yeah so you\ncan be so you can join and ask us all\nthe questions\nyeah that you want and that might help\nyou solve the challenge in case um you\ndon't want to wait for our open Office\nhours or something comes up and during\nthese days you can also ask the\nquestions at any time at the SFP\nCommunity there you can also see the\nkickoff blog post and then you can just\nwrite your questions as a comment to\nthis blog post now we will be monitoring\nthat and then we'll also try to help you\nwith um\nthis in the sap community\nyeah the idea is that we all work and\nlearn together yeah so feel free to work\nin teams if you want if you want to\nparticipate alone that's also fine but\nalso we want you to share your\nexperience in our final call where you\nalso can present your results yeah that\nyou shared it also with all the other\nparticipants\nyes so the idea is that everyone can\nreally improve their skills we all can\nlearn something during this Challenge\nand we can learn as much as we can also\nfrom each other\nI already mentioned we also have a final\ncall where you can all present your\nresults you can you don't have to but we\nwould highly appreciate it if you prefer\nnot to present it during a call you can\nalso write a blog post about it and post\nit on the sap Community challenge so\nit's up to you what you want and then we\nhave our experts who then will decide\nwho wins the hackathon now we also have\nsome nice prizes for you\nso I would say give it your best shot\nyeah do your very best during your our\nChallenge and then try to win the\nhackathon\nyeah let's maybe talk a little bit more\nabout a challenge\nand here's our evaluation criteria\nlike I said you have a challenge so you\nhave one use case that you should solve\nwith the sap Hana machine learning\nAsiana presented to you it's up to you\nif you want to use the automated\npredictive library or the predictive\nanalysis library but you should\ndefinitely use the things which are\navailable on the Hana cloud\nand we are also looking for an appealing\npresentation so give it a clear message\nand also think about for whom are you\nbuilding this yes so you should also\nthink about the business context maybe\nyou have a Persona in mind for whom\nyou're building this and then\ngive it a clear message", "doc_id": "339ffd2d-49e9-47f2-92d4-6976df9bc82a", "embedding": null, "doc_hash": "bd8ac4fc563266db0a6beb7af24cc99dea11aac48bbe896e4b4073213da70d37", "extra_info": null, "node_info": {"start": 16233, "end": 20221, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "367d2294-9bac-4a86-82e5-5548e5f89a8d", "3": "931fb36c-94b6-461d-a932-febc9bf6b40f"}}, "__type__": "1"}, "931fb36c-94b6-461d-a932-febc9bf6b40f": {"__data__": {"text": "Persona in mind for whom\nyou're building this and then\ngive it a clear message make it really\nnice presentation and we are not just\nlooking for the highest security\nposition or recall of course this is\nalso important but we are also looking\nfor the best and catchy story yeah so\njust make it a nice and fun presentation\nand I think you're good to go\nokay then on the next slide we have all\nthe details about our challenge\nyeah here we go so it's all about\nemployee churn now Susan wrote this\nquite provocatively with I quit yeah we\nthought you know during the times where\neveryone is looking for the best talents\nthis is really important you the use\ncase to really yeah\nretain yeah your most skilled people\nmake him happy so that they stay with\nyou as long as they can\nso this is then what it's all about yeah\nyou should predict which employees will\nbe leaving the company within the next\n12 months yeah and\nyeah I think this is a highly\ninteresting case because when I talk to\nmanagers sometimes um they think when\nsomeone has a new haircut then that\nmight be the highest indication but we\nthink the data can do better yeah so\nthat's why we prepared a lot of yeah\ndifferent\num\nyeah data are the different factors for\nyou influencing factors so you can\nchoose the one which really have an\ninfluence yeah I hope you remind that\nhaving a new haircut or not is not\nincluded in the data set because we felt\nthat is not so relevant yeah\num so let's have a bit more of a look\non the data Kristoff\nand maybe you can press on the play\nbutton so we can see that so this is um\nactually the data that we prepared for\nyou yeah you see you have a lot of\ndifferent influencing factors that you\ncan see here it's basically everything\nso it's the age it's a gender so the\nclassical Master data that we know about\nour employees but also the things here\nis it a full-time employee or not\ndid they change already yeah within the\ncompanies on which functional area did\nthey work before in which country did\nthey work before how long was have they\nbeen with the formal\num yeah with the formal position was it\nan external hire or something and also\nwhen they changed the position was it an\nintro functional move or not so\nbasically everything we could think of\nthat really has an influence or so\ntypical data that you also have in your\nHR System you can find data here this\nlink via GitHub repository and there's\nalso a PDF attached that gives you a\nreally detailed description of each of\nthe fields okay so that you can see what\nis there in each field\nand what does each of these entries mean\nin case you have some questions about it\nyou can of course again come back to us\nas you can see here on the right the\nFlight Risk this is from the historic\ndata yeah so that you see who left the\ncompany actually in the last 12 months\nand this is what we will use to train it\nyeah but you will use to train it so you\ncan then of course apply it to the new\nemployees and see who is up next yeah\num who has a really high churn rate and\nalso maybe you can also find some\nreasons why someone is leaving which\nthen could prevent yeah so which could\nthen be a good tip for our managers so\nthey can do something about it so that\nthey will stay with us\nokay that's it from The Challenge\nlike I said if you have any question you\ncan ask them now in the chat or also\nlater on\num I will head over to Andreas to talk a\nbit more about the organization\nyeah super thank you uh Sarah so if we\njust stay on the slides Kristoff if we\njust uh\ncontinuous with it that'd be perfect\njust coming up if you just go\nto the next slide please yeah\nsuper thanks so much so I'm sure you all\nKeen to to get started now you heard\nabout the machine learning in Hana Cloud\nyou've seen it you heard about the\nchallenge so now to some practical\ndetails I'll know the next three weeks\nreally now is going to continue\nand today at the time of presenting or\nrecording it is in November the 28th\nand you have now three weeks to work on\nthis challenge to implement at the end\nof these three weeks to present your\nresults as Sarah has explained\num", "doc_id": "931fb36c-94b6-461d-a932-febc9bf6b40f", "embedding": null, "doc_hash": "71bf7056e234b692c38e72d9013a660a0aae139c583dcc285318127d4234146d", "extra_info": null, "node_info": {"start": 20222, "end": 24300, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "339ffd2d-49e9-47f2-92d4-6976df9bc82a", "3": "d5187b22-e396-441d-af05-5cd79a07f701"}}, "__type__": "1"}, "d5187b22-e396-441d-af05-5cd79a07f701": {"__data__": {"text": "the end\nof these three weeks to present your\nresults as Sarah has explained\num so the first sort of um contact with\na few participants already had last week\nwhere we offered connectivity sessions\nfor people uh to connect from the local\npython environment to the Hana Cloud\nwhich I understand has all been working\nvery well so far\nand as part of the support that we are\nproviding now to help you so um bring\nthe implementation we're providing these\nopen Office hours that we've already\nmentioned but here we have these dates\nof these open Office hours and together\nwith a link where you find the exact\nhours and due to the global nature of\nthis challenge we're offering different\ntime slots\nyeah the first line that you see at the\nbottom of the of the slide is for the\nEuropean and Asia pack time zone and the\nsecond line further below is for the\nAmericas so that everybody has the\nchance not to talk to someone during\nnormal working hours of course\nand you will be supported by a global\nteam of expert that we see on the next\nslide just off if you have a kind\nthanks and you see now we have experts\nin North America in South America Peru\ncan Andres we have experts in in Asia\nPacific Raymond but also the People\nbased in Europe that I am called at the\nmoment so we're not always available on\nall of the course calls there'll be of\ncourse but no there's I hope enough\noptions to get in touch and discuss with\nthat support\nand then essentially the assessment\nbreaks down in five major steps\nthat we will see here\nso first of all you need to implement\nthe prerequisite prerequisite as the\nalready listed listed on the blocks that\nare provided\nessentially setting up your python\nenvironment I'm installing the San ml\nlibrary that allows you to connect to a\nHana system\nand then once you have this set up you\nyou connect you test that connection\nthat this is working well and once you\nknow you have a connectivity you may\nwant to get some practice and here we\nprovide tutorials with different data\nsets that gives you guidance that gives\nyou code to get started to experiment\nand once you feel sort of comfortable to\ntry out you know your skills on this\ndata set now on the churn scenario this\nwould be number four and most likely\nthis is of course where you spend most\nof the time and there's no right there's\nno wrong in data science there's a lot\nof going back and forth where it Bridges\nso you might um experience that as well\nin this scenario and eventually you know\nwe are looking extremely forward to what\nyou're presenting what you created so\nthis will be very nice and um at the end\nof the next three weeks\nand finally I'm a little bit more detail\non the next slide thank you Kristoff you\nknow where it's important to point out\nthat the free trial that you always have\naccess to with Hana cloud and data\nwarehouse Cloud but these are not\nsufficient to use the machine learning\nthis is simply not enabled in the free\ntrials\nthey exist in the core product and some\nparticipants already have for example\ntheir own data Mouse cloud system that\nthey're using so um be sure to use the\ncredentials that we're providing\nspecifically now for this community\nchallenge if you don't have your own\nsystem\nmany of you have already received these\nyou just need to reach out by email so\nthat we can respond with the logon\ncredentials if you haven't received them\nyet\nhere is the email address please send us\na note and very quickly in Return of\ncourse you get these credentials and on\nthat slide we're also listing again the\nblock with the exact powers for these\nsessions that we're providing where you\ncan get in touch sometimes it is easier\nto talk and we hope even if possible if\nneeded we can do a little breakout\nsession that we can discuss in one to\none maybe looking at your individual\nsystems but it's also absolutely fine as\nyou prefer to post a question for\nexample here on the on the thread that's\nalso listed that anybody can to see a\nquestion we can respond to everyone to\nsee so that everybody benefits from the\ndiscussions that are going on so the\nchoice is completely down to you how\nyou'd like to get in touch\nwith that we explain the challenge and\nso many of you are ready", "doc_id": "d5187b22-e396-441d-af05-5cd79a07f701", "embedding": null, "doc_hash": "9c559a73638c200ac620b5ca9cee17ed1fffa20c49639f0d311b8b9c5ff61176", "extra_info": null, "node_info": {"start": 24300, "end": 28478, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "931fb36c-94b6-461d-a932-febc9bf6b40f", "3": "cc2300fa-d504-420c-8b1d-ad65b05ac1f1"}}, "__type__": "1"}, "cc2300fa-d504-420c-8b1d-ad65b05ac1f1": {"__data__": {"text": "get in touch\nwith that we explain the challenge and\nso many of you are ready to go\nand I headed back to Susan and maybe\nyou've already had some questions in the\nQ a\nperfect so thank you Andreas and you're\nexactly right there is a lot going on in\nour q a tool\nso\num Kristoff was already really really\nbusy answering some of these questions\nbut I think it's good to also have the\nanswers on The Talk track as well\nso first question we should maybe answer\nis are we allowed to use local libraries\nfor fitting\nso yeah maybe I can can take that or do\nyou want to go\nyeah have you detect\nIve you know so basically it's a Hana\nmachine learning challenge we might be a\nlittle biased towards using the engines\nnow\num in Hana Cloud obviously so this is\nreally the purpose\num so I think for that challenge so uh\nit clearly it would be nice to use the\nengines provided inside time outside the\ngel\nperfect yeah so the next question\nclosely related to the first one is can\nI also use sky keflow and Pipelines\nyeah I think that would be the same\nanswer\nyes so you're here we're really biased\ntowards Hana Cloud so um this is a\nnatural Challenge and we would really\nreally appreciate if you could also use\nhow I call to solve our challenge\nso next question in the Q a tool I'm\njust scanning is can you share the\nnotebook from the demo so Yannick this\none would go to you I guess\nof course yep so we'll\num have the blog post for for the demo\nwe showed and also um The Notebook is\navailable in a GitHub repository which\nwe would share yeah\nperfect yes so for your information the\nGitHub repositories also already posted\nto the chat so you can just click the\nlink out of our YouTube chat and open it\nup so you also get our repository that\nwas used for the demo let me scan so\nwe're having one other question or there\nare also coming more questions and I can\nsee\num it is regarding the data set so um\nanus is asking is this anonymized really\nlike data where it is possible to get\nsome real insights or random data and I\nremember we talked a lot about the data\nset so maybe you want to comment on this\none\num yeah so of course\num for for this community challenge we\ncouldn't give out\num real data\num especially in for such employee\nJournal use cases so\num it's simulated data but of course we\nmade sure to\nmake it quite tricky and um that it's\nalso very close to the reality of such a\nuse case\nperfect so um please for everyone who's\nstill with us in the call if your\nquestion is answered and you're still\nhaving like open points please let us\nknow and we're happy to to once again\nanswer questions if there are still\nstill things open\nso\num next question we will definitely post\nuh the link for yannick's blog in the\nchat in just a second and then there is\none last open question\nfrom Sergey\num there is no ranking submission with\nunseen data is that correct\nI'll take that yeah so that is that is\ncorrect yes\num because here the data that we're\nworking with as the senegade bank now is\nnot realistic data it's realistic but\nwith real data and for that reason we\nthought it's uh it's very tricky you\nknow to then test the model on a true\nhold out sample so we are probably more\nlooking for creativity in the way you\napproach it\nperfect so thank you Andreas um Sega let\nus know if this answers your question\nbut I think this was a really crisp and\nprecise answer so we should be good here\nare there any other questions open I\nhope I have not overlooked them in the\nchat as this one is really crowded\nso last call for any questions\nokay so it looks a little quieter now\nbut\nyep perfect so say this question was\nanswered so I think we can close it off\na little earlier\num that was a great presentation thank\nyou so much for sharing your challenge\nand I think I can speak for the whole\nteam\nwe are really really excited um to kick\nthe challenge finally off and to see a\nlot of great results", "doc_id": "cc2300fa-d504-420c-8b1d-ad65b05ac1f1", "embedding": null, "doc_hash": "51fb6c3cf64bba5d84b6043630264f0714fc4aa75bd22835acd6e1f50141a715", "extra_info": null, "node_info": {"start": 28483, "end": 32349, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "d5187b22-e396-441d-af05-5cd79a07f701", "3": "e002246b-8e7e-40c6-9de9-7faebdc4c4ab"}}, "__type__": "1"}, "e002246b-8e7e-40c6-9de9-7faebdc4c4ab": {"__data__": {"text": "um to kick\nthe challenge finally off and to see a\nlot of great results oh sorry I just got\none question in the chat so let's come\nback to to answering this one so\nEnriquez asking what is preferable to\nuse Sac or Hana Cloud for doing\nPredictive Analytics\nfor this one\num it depends basically on your skills\nso with sap analytics Cloud actually\nuses the same mathematics in the\nbackground as the automated predictive\nLibrary so if you're more of a business\nuser and you're not so familiar with\nlike Yannick showed you python coding or\nR coding and then you feel probably more\ncomfortable with using sap analytics\nCloud because there in the function\nwhich is called smart predict you can\njust with a few clicks also use the\nautomated predictive Library without any\ncode\nand but of course you're a bit Limited\nin sap analytics Cloud you could just\nuse the automated predictive Library if\nyou want to have more flexibility use\ndifferent algorithms like Yannick showed\nyou a random forest and then you will\nprobably use the predictive analysis\nlibrary and then you definitely need to\ngo to the Hana machine learning part and\nsap Hana cloud\nI hope that helps you\nperfect so thank you Sarah for answering\nthis and I think this was a really\ncomprehensive summary\nso let me close it off once again\num thanks for joining us today\num we're excited to see a lot of um\nchallenge submissions and as Andreas\nbroadly explained we're here for you so\nif you're running into any issues\nproblems troubles whatever please feel\nfree to reach out contact us join us for\nthe open Office hours comment on our\nblog posts we really want to tackle the\nchallenge together with you yeah so\nthanks and uh talk to you maybe in one\nof our open Office hours\nbye bye\nhi\n", "doc_id": "e002246b-8e7e-40c6-9de9-7faebdc4c4ab", "embedding": null, "doc_hash": "08114a63e8aff8cb079e998c55ce1b425c607bbcb8a6b1f7f527d9801f150418", "extra_info": null, "node_info": {"start": 32342, "end": 34076, "_node_type": "1"}, "relationships": {"1": "6555f559-656f-4f88-8982-8219e333a9f4", "2": "cc2300fa-d504-420c-8b1d-ad65b05ac1f1"}}, "__type__": "1"}}, "docstore/ref_doc_info": {"6555f559-656f-4f88-8982-8219e333a9f4": {"doc_ids": ["1fa14299-49e1-4ab4-900c-89677384657e", "745c7409-b389-41e2-ae58-7fae1f5ade74", "083d227d-1551-482c-b803-8065cb6500c0", "367d2294-9bac-4a86-82e5-5548e5f89a8d", "339ffd2d-49e9-47f2-92d4-6976df9bc82a", "931fb36c-94b6-461d-a932-febc9bf6b40f", "d5187b22-e396-441d-af05-5cd79a07f701", "cc2300fa-d504-420c-8b1d-ad65b05ac1f1", "e002246b-8e7e-40c6-9de9-7faebdc4c4ab"], "extra_info": {}}}}